{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T11:04:08.493527Z","iopub.execute_input":"2024-02-24T11:04:08.493882Z","iopub.status.idle":"2024-02-24T11:04:08.910109Z","shell.execute_reply.started":"2024-02-24T11:04:08.493853Z","shell.execute_reply":"2024-02-24T11:04:08.908990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Following the Standard Pattern to Solve a Data Science Problem\n\"\"\"\nStep 1: Define the Problem\nProject Summary: Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. \nWe've received a transmission from four lightyears away and things aren't looking good.\n\nThe Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, \nthe vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n\nWhile rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided \nwith a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. \nThough the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n\nTo help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly \nusing records recovered from the spaceship’s damaged computer system.\n\nHelp save them and change history!\"\"\"\n\n\"\"\"\nStep 2: Gather the Data\nThe dataset is also given to us with test and train data at Spaceship Titanic\n\"\"\"\n\n\"\"\"\nStep 3: Prepare Data for Consumption\nSince step 2 was provided to us, so is step 3. \nTherefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. \nThus, only data cleaning is in scope.\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:08.913162Z","iopub.execute_input":"2024-02-24T11:04:08.915181Z","iopub.status.idle":"2024-02-24T11:04:08.922568Z","shell.execute_reply.started":"2024-02-24T11:04:08.915141Z","shell.execute_reply":"2024-02-24T11:04:08.921877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Core\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n#from sklearn.metrics import roc_auc_score, plot_roc_curve, roc_curve\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.decomposition import PCA\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.utils import resample\n\n# Models\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:33:33.621081Z","iopub.execute_input":"2024-02-24T11:33:33.621492Z","iopub.status.idle":"2024-02-24T11:33:33.641836Z","shell.execute_reply.started":"2024-02-24T11:33:33.621463Z","shell.execute_reply":"2024-02-24T11:33:33.640479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save to df\npd.set_option('display.max_columns', None)\ntrain = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest = pd.read_csv('../input/spaceship-titanic/test.csv')\n\n# Shape and preview\nprint('Train set shape:', train.shape)\nprint('Test set shape:', test.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:25.328384Z","iopub.execute_input":"2024-02-24T11:04:25.329105Z","iopub.status.idle":"2024-02-24T11:04:25.430713Z","shell.execute_reply.started":"2024-02-24T11:04:25.329074Z","shell.execute_reply":"2024-02-24T11:04:25.429383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for duplicates\n\ntrain.duplicated().sum(), test.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:25.431639Z","iopub.execute_input":"2024-02-24T11:04:25.431957Z","iopub.status.idle":"2024-02-24T11:04:25.466206Z","shell.execute_reply.started":"2024-02-24T11:04:25.431932Z","shell.execute_reply":"2024-02-24T11:04:25.465147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EDA\n# Figure size\n\nplt.figure(figsize=(10, 6))\n\n# Countplot\nsns.countplot(x='Transported', data=train, palette='viridis')\ntotal = len(train['Transported'])\nfor p in plt.gca().patches:\n    height = p.get_height()\n    plt.text(p.get_x() + p.get_width() / 2., height + 0.1,\n             '{:.1%}'.format(height/total),\n             ha=\"center\", fontsize=12)\n\nplt.title(\"Target distribution\")\nplt.show()\n\n\"We have a balanced target value - No need for Over/Undersampling\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:25.467514Z","iopub.execute_input":"2024-02-24T11:04:25.467932Z","iopub.status.idle":"2024-02-24T11:04:25.710957Z","shell.execute_reply.started":"2024-02-24T11:04:25.467903Z","shell.execute_reply":"2024-02-24T11:04:25.709801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for all na values\n\ntrain.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:25.712294Z","iopub.execute_input":"2024-02-24T11:04:25.712625Z","iopub.status.idle":"2024-02-24T11:04:25.724907Z","shell.execute_reply.started":"2024-02-24T11:04:25.712597Z","shell.execute_reply":"2024-02-24T11:04:25.723565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Continuous features\n# Figure size\nplt.figure(figsize=(10,4))\nsns.histplot(data=train, x='Age', hue='Transported', binwidth=1, kde=True)\nplt.title('Age distribution')\nplt.xlabel('Age (years)')\n\n\"\"\"\n0-18 year olds were more likely to be transported than not.\n18-25 year olds were less likely to be transported than not.\nOver 25 year olds were about equally likely to be transported than not.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:25.725863Z","iopub.execute_input":"2024-02-24T11:04:25.726162Z","iopub.status.idle":"2024-02-24T11:04:26.564034Z","shell.execute_reply.started":"2024-02-24T11:04:25.726139Z","shell.execute_reply":"2024-02-24T11:04:26.562914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Age'].skew()\n#Perfect Skew = 0\n#Moderate Skew is between -0.5 to +0.5 ie fairly symmetric and can be considered norm dist","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:26.565488Z","iopub.execute_input":"2024-02-24T11:04:26.565946Z","iopub.status.idle":"2024-02-24T11:04:26.573676Z","shell.execute_reply.started":"2024-02-24T11:04:26.565906Z","shell.execute_reply":"2024-02-24T11:04:26.572644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New features - training set\ntrain['Age_group']=np.nan\ntrain.loc[train['Age']<=12,'Age_group']='Age_0-12'\ntrain.loc[(train['Age']>12) & (train['Age']<18),'Age_group']='Age_13-17'\ntrain.loc[(train['Age']>=18) & (train['Age']<=25),'Age_group']='Age_18-25'\ntrain.loc[(train['Age']>25) & (train['Age']<=30),'Age_group']='Age_26-30'\ntrain.loc[(train['Age']>30) & (train['Age']<=50),'Age_group']='Age_31-50'\ntrain.loc[train['Age']>50,'Age_group']='Age_51+'\n\n# New features - test set\ntest['Age_group']=np.nan\ntest.loc[test['Age']<=12,'Age_group']='Age_0-12'\ntest.loc[(test['Age']>12) & (test['Age']<18),'Age_group']='Age_13-17'\ntest.loc[(test['Age']>=18) & (test['Age']<=25),'Age_group']='Age_18-25'\ntest.loc[(test['Age']>25) & (test['Age']<=30),'Age_group']='Age_26-30'\ntest.loc[(test['Age']>30) & (test['Age']<=50),'Age_group']='Age_31-50'\ntest.loc[test['Age']>50,'Age_group']='Age_51+'\n\n# Plot distribution of new features\nplt.figure(figsize=(10,4))\ng=sns.countplot(data=train, x='Age_group', hue='Transported', order=['Age_0-12','Age_13-17','Age_18-25','Age_26-30','Age_31-50','Age_51+'])\nplt.title('Age group distribution')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:26.577923Z","iopub.execute_input":"2024-02-24T11:04:26.578302Z","iopub.status.idle":"2024-02-24T11:04:26.931693Z","shell.execute_reply.started":"2024-02-24T11:04:26.578273Z","shell.execute_reply":"2024-02-24T11:04:26.930714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp_feats=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n# New features - training set\ntrain['Expenditure']=train[exp_feats].sum(axis=1)\ntrain['No_spending']=(train['Expenditure']==0).astype(int)\n\n# New features - test set\ntest['Expenditure']=test[exp_feats].sum(axis=1)\ntest['No_spending']=(test['Expenditure']==0).astype(int)\n\n# Plot distribution of new features\nfig=plt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nsns.histplot(data=train, x='Expenditure', hue='Transported', bins=200)\nplt.title('Total expenditure (truncated)')\nplt.ylim([0,200])\nplt.xlim([0,20000])\n\nplt.subplot(1,2,2)\nsns.countplot(data=train, x='No_spending', hue='Transported')\nplt.title('No spending indicator')\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:26.932991Z","iopub.execute_input":"2024-02-24T11:04:26.934024Z","iopub.status.idle":"2024-02-24T11:04:28.377670Z","shell.execute_reply.started":"2024-02-24T11:04:26.933985Z","shell.execute_reply":"2024-02-24T11:04:28.376657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New feature - Group\ntrain['Group'] = train['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\ntest['Group'] = test['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n\n# New feature - Group size ranging from 1-8\ntrain['Group_size']=train['Group'].map(train['Group'].value_counts())\ntest['Group_size']=test['Group'].map(test['Group'].value_counts())\n\n# Plot distribution of new features\nplt.figure(figsize=(20,4))\nplt.subplot(1,2,1)\nsns.histplot(data=train, x='Group', hue='Transported', binwidth=1)\nplt.title('Group')\n\nplt.subplot(1,2,2)\nsns.countplot(data=train, x='Group_size', hue='Transported')\nplt.title('Group size')\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:04:28.379159Z","iopub.execute_input":"2024-02-24T11:04:28.379487Z","iopub.status.idle":"2024-02-24T11:05:11.171465Z","shell.execute_reply.started":"2024-02-24T11:04:28.379453Z","shell.execute_reply":"2024-02-24T11:05:11.170265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New feature\ntrain['Solo']=(train['Group_size']==1).astype(int)\ntest['Solo']=(test['Group_size']==1).astype(int)\n\n# New feature distribution\nplt.figure(figsize=(10,4))\nsns.countplot(data=train, x='Solo', hue='Transported')\nplt.title('Passenger travelling solo or not')\nplt.ylim([0,3000])\n\n\n\"\"\"\nPerson travelling Solo have high chance of NOT reaching the destination compare to people travelling in groups\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:11.173034Z","iopub.execute_input":"2024-02-24T11:05:11.174144Z","iopub.status.idle":"2024-02-24T11:05:11.441465Z","shell.execute_reply.started":"2024-02-24T11:05:11.174100Z","shell.execute_reply":"2024-02-24T11:05:11.440681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create another figure\nplt.figure(figsize=(10,6))\n\n# Start with positve examples\nplt.scatter(train.Age[train['Transported']==True], \n            train.Expenditure[train['Transported']==True], \n            c=\"salmon\") # define it as a scatter figure\n\n# Now for negative examples, we want them on the same plot, so we call plt again\nplt.scatter(train.Age[train['Transported']==False], \n            train.Expenditure[train['Transported']==False], \n            c=\"lightblue\") # axis always come as (x, y)\n\n# Add some helpful info\nplt.title(\"Age Vs Expenditure\")\nplt.xlabel(\"Age\")\nplt.legend([\"Not Transported\", \"Transported\"])\nplt.ylabel(\"Expenditure\");","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:11.442736Z","iopub.execute_input":"2024-02-24T11:05:11.443416Z","iopub.status.idle":"2024-02-24T11:05:12.037691Z","shell.execute_reply.started":"2024-02-24T11:05:11.443388Z","shell.execute_reply":"2024-02-24T11:05:12.036848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Categorical features\n# Categorical features\ncat_feats=['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n\n# Plot categorical features\nfig=plt.figure(figsize=(10,16))\nfor i, var_name in enumerate(cat_feats):\n    ax=fig.add_subplot(4,1,i+1)\n    sns.countplot(data=train, x=var_name, axes=ax, hue='Transported')\n    ax.set_title(var_name)\nfig.tight_layout()  # Improves appearance a bit\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:12.038744Z","iopub.execute_input":"2024-02-24T11:05:12.039773Z","iopub.status.idle":"2024-02-24T11:05:13.038899Z","shell.execute_reply.started":"2024-02-24T11:05:12.039715Z","shell.execute_reply":"2024-02-24T11:05:13.037821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train['VIP'].isin([True])]","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:13.040283Z","iopub.execute_input":"2024-02-24T11:05:13.041328Z","iopub.status.idle":"2024-02-24T11:05:13.074613Z","shell.execute_reply.started":"2024-02-24T11:05:13.041290Z","shell.execute_reply":"2024-02-24T11:05:13.073049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking VIP count\n#EDA\n# Figure size\n\nplt.figure(figsize=(10, 6))\n# Countplot\nsns.countplot(x='VIP', data=train, palette='viridis')\ntotal = len(train['VIP'])\nfor p in plt.gca().patches:\n    height = p.get_height()\n    plt.text(p.get_x() + p.get_width() / 2., height + 0.1,\n             '{:.1%}'.format(height/total),\n             ha=\"center\", fontsize=12)\n\nplt.title(\"VIP distribution\")\nplt.show()\n\n\"\"\"95% people are no VIP\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:13.076069Z","iopub.execute_input":"2024-02-24T11:05:13.076472Z","iopub.status.idle":"2024-02-24T11:05:13.313520Z","shell.execute_reply.started":"2024-02-24T11:05:13.076442Z","shell.execute_reply":"2024-02-24T11:05:13.312356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:13.315001Z","iopub.execute_input":"2024-02-24T11:05:13.315346Z","iopub.status.idle":"2024-02-24T11:05:13.338119Z","shell.execute_reply.started":"2024-02-24T11:05:13.315318Z","shell.execute_reply":"2024-02-24T11:05:13.336927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vte = train.groupby(['VIP', 'Transported'])['Expenditure'].count().unstack()\n\n\n# Heatmap of missing values\nplt.figure(figsize=(10,4))\nsns.heatmap(vte.T, annot=True, fmt='g', cmap='coolwarm')\n\n#We can consider removing VIP feature ","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:13.340016Z","iopub.execute_input":"2024-02-24T11:05:13.340745Z","iopub.status.idle":"2024-02-24T11:05:13.615318Z","shell.execute_reply.started":"2024-02-24T11:05:13.340714Z","shell.execute_reply":"2024-02-24T11:05:13.613983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cabin location\n#Extract deck, number and side from cabin feature. \n\n# Replace NaN's with outliers for now (so we can split feature)\ntrain['Cabin'].fillna('Z/9999/Z', inplace=True)\ntest['Cabin'].fillna('Z/9999/Z', inplace=True)\n\n# New features - training set\ntrain['Cabin_deck'] = train['Cabin'].apply(lambda x: x.split('/')[0])\ntrain['Cabin_number'] = train['Cabin'].apply(lambda x: x.split('/')[1]).astype(int)\ntrain['Cabin_side'] = train['Cabin'].apply(lambda x: x.split('/')[2])\n\n# New features - test set\ntest['Cabin_deck'] = test['Cabin'].apply(lambda x: x.split('/')[0])\ntest['Cabin_number'] = test['Cabin'].apply(lambda x: x.split('/')[1]).astype(int)\ntest['Cabin_side'] = test['Cabin'].apply(lambda x: x.split('/')[2])\n\n# Put Nan's back in (we will fill these later)\ntrain.loc[train['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\ntrain.loc[train['Cabin_number']==9999, 'Cabin_number']=np.nan\ntrain.loc[train['Cabin_side']=='Z', 'Cabin_side']=np.nan\ntest.loc[test['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\ntest.loc[test['Cabin_number']==9999, 'Cabin_number']=np.nan\ntest.loc[test['Cabin_side']=='Z', 'Cabin_side']=np.nan\n\n# Drop Cabin (we don't need it anymore)\ntrain.drop('Cabin', axis=1, inplace=True)\ntest.drop('Cabin', axis=1, inplace=True)\n\n# Plot distribution of new features\nfig=plt.figure(figsize=(10,12))\nplt.subplot(3,1,1)\nsns.countplot(data=train, x='Cabin_deck', hue='Transported', order=['A','B','C','D','E','F','G','T'])\nplt.title('Cabin deck')\n\nplt.subplot(3,1,2)\nsns.histplot(data=train, x='Cabin_number', hue='Transported',binwidth=20)\nplt.vlines(300, ymin=0, ymax=200, color='black')\nplt.vlines(600, ymin=0, ymax=200, color='black')\nplt.vlines(900, ymin=0, ymax=200, color='black')\nplt.vlines(1200, ymin=0, ymax=200, color='black')\nplt.vlines(1500, ymin=0, ymax=200, color='black')\nplt.vlines(1800, ymin=0, ymax=200, color='black')\nplt.title('Cabin number')\nplt.xlim([0,2000])\n\nplt.subplot(3,1,3)\nsns.countplot(data=train, x='Cabin_side', hue='Transported')\nplt.title('Cabin side')\nfig.tight_layout()\n\n#Cabin T can be removed","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:13.616991Z","iopub.execute_input":"2024-02-24T11:05:13.617337Z","iopub.status.idle":"2024-02-24T11:05:16.099478Z","shell.execute_reply.started":"2024-02-24T11:05:13.617308Z","shell.execute_reply":"2024-02-24T11:05:16.098402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:16.100988Z","iopub.execute_input":"2024-02-24T11:05:16.101350Z","iopub.status.idle":"2024-02-24T11:05:16.128941Z","shell.execute_reply.started":"2024-02-24T11:05:16.101322Z","shell.execute_reply":"2024-02-24T11:05:16.127786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New features - training set\ntrain['Cabin_region1']=(train['Cabin_number']<300).astype(int)   # one-hot encoding\ntrain['Cabin_region2']=((train['Cabin_number']>=300) & (train['Cabin_number']<600)).astype(int)\ntrain['Cabin_region3']=((train['Cabin_number']>=600) & (train['Cabin_number']<900)).astype(int)\ntrain['Cabin_region4']=((train['Cabin_number']>=900) & (train['Cabin_number']<1200)).astype(int)\ntrain['Cabin_region5']=((train['Cabin_number']>=1200) & (train['Cabin_number']<1500)).astype(int)\ntrain['Cabin_region6']=((train['Cabin_number']>=1500) & (train['Cabin_number']<1800)).astype(int)\ntrain['Cabin_region7']=(train['Cabin_number']>=1800).astype(int)\n\n# New features - test set\ntest['Cabin_region1']=(test['Cabin_number']<300).astype(int)   # one-hot encoding\ntest['Cabin_region2']=((test['Cabin_number']>=300) & (test['Cabin_number']<600)).astype(int)\ntest['Cabin_region3']=((test['Cabin_number']>=600) & (test['Cabin_number']<900)).astype(int)\ntest['Cabin_region4']=((test['Cabin_number']>=900) & (test['Cabin_number']<1200)).astype(int)\ntest['Cabin_region5']=((test['Cabin_number']>=1200) & (test['Cabin_number']<1500)).astype(int)\ntest['Cabin_region6']=((test['Cabin_number']>=1500) & (test['Cabin_number']<1800)).astype(int)\ntest['Cabin_region7']=(test['Cabin_number']>=1800).astype(int)\n\n# Plot distribution of new features - giving importance to subsequent cabin region values\nplt.figure(figsize=(10,4))\ntrain['Cabin_regions_plot']=(train['Cabin_region1']+2*train['Cabin_region2']+3*train['Cabin_region3']+4*train['Cabin_region4']+5*train['Cabin_region5']+6*train['Cabin_region6']+7*train['Cabin_region7']).astype(int)\nsns.countplot(data=train, x='Cabin_regions_plot', hue='Transported')\nplt.title('Cabin regions')\ntrain.drop('Cabin_regions_plot', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:16.130456Z","iopub.execute_input":"2024-02-24T11:05:16.130799Z","iopub.status.idle":"2024-02-24T11:05:16.528422Z","shell.execute_reply.started":"2024-02-24T11:05:16.130745Z","shell.execute_reply":"2024-02-24T11:05:16.527262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As the space-ship titanic event is happening, cabin region based on cabin number is an important parameter \n# as when the disaster happens, cabin region will play and important role deciding if the passenger will be transported or NOT","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:16.529876Z","iopub.execute_input":"2024-02-24T11:05:16.530244Z","iopub.status.idle":"2024-02-24T11:05:16.535004Z","shell.execute_reply.started":"2024-02-24T11:05:16.530214Z","shell.execute_reply":"2024-02-24T11:05:16.533551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Last name - Same last name would be same HomePlanet, same group\n#Calculate family size from last name.\n\n# Replace NaN's with outliers for now (so we can split feature)\ntrain['Name'].fillna('Unknown Unknown', inplace=True)\ntest['Name'].fillna('Unknown Unknown', inplace=True)\n\n# New feature - Surname\ntrain['Surname']=train['Name'].str.split().str[-1]\ntest['Surname']=test['Name'].str.split().str[-1]\n\n# New feature - Family size\ntrain['Family_size']=train['Surname'].map(test['Surname'].value_counts())\ntest['Family_size']=test['Surname'].map(test['Surname'].value_counts())\n\n# Put Nan's back in (we will fill these later) - handling improper dataset\ntrain.loc[train['Surname']=='Unknown','Surname']=np.nan\ntrain.loc[train['Family_size']>100,'Family_size']=np.nan\n\ntest.loc[test['Surname']=='Unknown','Surname']=np.nan\ntest.loc[test['Family_size']>100,'Family_size']=np.nan\n\n# Drop name (we don't need it anymore)\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)\n\n# New feature distribution\nplt.figure(figsize=(12,4))\nsns.countplot(data=train, x='Family_size', hue='Transported')\nplt.title('Family size')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:16.536427Z","iopub.execute_input":"2024-02-24T11:05:16.536804Z","iopub.status.idle":"2024-02-24T11:05:17.032385Z","shell.execute_reply.started":"2024-02-24T11:05:16.536773Z","shell.execute_reply":"2024-02-24T11:05:17.031320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EDA Over, Time to Clean the data","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.033738Z","iopub.execute_input":"2024-02-24T11:05:17.034083Z","iopub.status.idle":"2024-02-24T11:05:17.037975Z","shell.execute_reply.started":"2024-02-24T11:05:17.034048Z","shell.execute_reply":"2024-02-24T11:05:17.037076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.039268Z","iopub.execute_input":"2024-02-24T11:05:17.039672Z","iopub.status.idle":"2024-02-24T11:05:17.071497Z","shell.execute_reply.started":"2024-02-24T11:05:17.039645Z","shell.execute_reply":"2024-02-24T11:05:17.070513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.pivot_table(index='Group',columns='HomePlanet', values='Expenditure', aggfunc='count')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.073349Z","iopub.execute_input":"2024-02-24T11:05:17.074075Z","iopub.status.idle":"2024-02-24T11:05:17.098924Z","shell.execute_reply.started":"2024-02-24T11:05:17.074046Z","shell.execute_reply":"2024-02-24T11:05:17.097820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Missing Values\n\n#Combine train and test\n# Labels and features\ny=train['Transported'].copy().astype(int)\nX=train.drop('Transported', axis=1).copy()\n\n# Concatenate dataframes\ndata=pd.concat([X, test], axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.106265Z","iopub.execute_input":"2024-02-24T11:05:17.106644Z","iopub.status.idle":"2024-02-24T11:05:17.131701Z","shell.execute_reply.started":"2024-02-24T11:05:17.106614Z","shell.execute_reply":"2024-02-24T11:05:17.130809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Explore missing values\n# Columns with missing values\nna_cols=data.columns[data.isna().any()].tolist()\n\n# Missing values summary\nmv=pd.DataFrame(data[na_cols].isna().sum(), columns=['Number_missing'])\nmv['Percentage_missing']=np.round(100*mv['Number_missing']/len(data),2)\nmv","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.133316Z","iopub.execute_input":"2024-02-24T11:05:17.133728Z","iopub.status.idle":"2024-02-24T11:05:17.163206Z","shell.execute_reply.started":"2024-02-24T11:05:17.133690Z","shell.execute_reply":"2024-02-24T11:05:17.162437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dealing with missing values 1 at a time","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.164264Z","iopub.execute_input":"2024-02-24T11:05:17.165146Z","iopub.status.idle":"2024-02-24T11:05:17.169192Z","shell.execute_reply.started":"2024-02-24T11:05:17.165118Z","shell.execute_reply":"2024-02-24T11:05:17.168024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Group'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.170417Z","iopub.execute_input":"2024-02-24T11:05:17.170721Z","iopub.status.idle":"2024-02-24T11:05:17.185284Z","shell.execute_reply.started":"2024-02-24T11:05:17.170697Z","shell.execute_reply":"2024-02-24T11:05:17.183981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.186996Z","iopub.execute_input":"2024-02-24T11:05:17.187440Z","iopub.status.idle":"2024-02-24T11:05:17.218249Z","shell.execute_reply.started":"2024-02-24T11:05:17.187410Z","shell.execute_reply":"2024-02-24T11:05:17.217207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data['Group'], data['HomePlanet'])\n\n#at group 3, europa is repeated 2 twice which means group 3 has 2 people both from Europa, \n    #therefore in crosstab, at group 3, europa is has 2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.219592Z","iopub.execute_input":"2024-02-24T11:05:17.220480Z","iopub.status.idle":"2024-02-24T11:05:17.401694Z","shell.execute_reply.started":"2024-02-24T11:05:17.220449Z","shell.execute_reply":"2024-02-24T11:05:17.400632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Group and HomePlanet\nGHP_gb=data.groupby(['Group','HomePlanet'])['HomePlanet'].count().unstack().fillna(0)\n\n\n\"\"\"\nEveryone in the same group comes from the same home planet. \nSo we can fill the missing HomePlanet values according to the group.\n(At least the ones where the group size is bigger than 1.)\n\"\"\"\n\nGHP_gb","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.402849Z","iopub.execute_input":"2024-02-24T11:05:17.403156Z","iopub.status.idle":"2024-02-24T11:05:17.427033Z","shell.execute_reply.started":"2024-02-24T11:05:17.403130Z","shell.execute_reply":"2024-02-24T11:05:17.425909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding group of similiar people in GROUP and takes its index value,\n#replace nan at HomePlanet with people of same group!\n\n# Missing values before\nHP_bef=data['HomePlanet'].isna().sum()\n\n# Passengers with missing HomePlanet and in a group with known HomePlanet\nGHP_index=data[data['HomePlanet'].isna()][(data[data['HomePlanet'].isna()]['Group']).isin(GHP_gb.index)].index\n#GHP_index = data[data['HomePlanet'].isna() & data['Group'].isin(GHP_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[GHP_index,'HomePlanet']=data.iloc[GHP_index,:]['Group'].map(lambda x: GHP_gb.idxmax(axis=1)[x])\n#data.loc[GHP_index, 'HomePlanet'] = data.loc[GHP_index, 'Group'].replace(GHP_gb.idxmax(axis=1))\n\n# Print number of missing values left\nprint('#HomePlanet missing values before:',HP_bef)\nprint('#HomePlanet missing values after:',data['HomePlanet'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.428338Z","iopub.execute_input":"2024-02-24T11:05:17.428743Z","iopub.status.idle":"2024-02-24T11:05:17.711575Z","shell.execute_reply.started":"2024-02-24T11:05:17.428716Z","shell.execute_reply":"2024-02-24T11:05:17.710491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()\n#HomePlanet and Group Done","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.712597Z","iopub.execute_input":"2024-02-24T11:05:17.712921Z","iopub.status.idle":"2024-02-24T11:05:17.739425Z","shell.execute_reply.started":"2024-02-24T11:05:17.712894Z","shell.execute_reply":"2024-02-24T11:05:17.738350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cshp = data.groupby(['CryoSleep','HomePlanet'])['HomePlanet'].count().unstack().fillna(0)\nplt.figure(figsize=(10,4))\nsns.heatmap(cshp.T, annot=True, fmt='g', cmap='coolwarm')\n\n#It would be risky to use CryoSleep to fill missing HomePlanet as it is binary and it also has missing values","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:17.740741Z","iopub.execute_input":"2024-02-24T11:05:17.741063Z","iopub.status.idle":"2024-02-24T11:05:18.024600Z","shell.execute_reply.started":"2024-02-24T11:05:17.741038Z","shell.execute_reply":"2024-02-24T11:05:18.023604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.026033Z","iopub.execute_input":"2024-02-24T11:05:18.026348Z","iopub.status.idle":"2024-02-24T11:05:18.054944Z","shell.execute_reply.started":"2024-02-24T11:05:18.026321Z","shell.execute_reply":"2024-02-24T11:05:18.053821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using other features to fill missing values- cabin deck\n# Joint distribution of CabinDeck and HomePlanet\nCDHP_gb=data.groupby(['Cabin_deck','HomePlanet'])['HomePlanet'].size().unstack().fillna(0)\n\n# Heatmap of missing values\nplt.figure(figsize=(10,4))\nsns.heatmap(CDHP_gb.T, annot=True, fmt='g', cmap='coolwarm')\n\n\"\"\"\nPassengers on decks A, B, C , T came from Europa.\nPassengers on deck G came from Earth.\nPassengers on decks D, E or F came from multiple planets.\n\"\"\"\n\n#As D,E,F has multiple values, we won't use use to find missing HomePlanet","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.056471Z","iopub.execute_input":"2024-02-24T11:05:18.057036Z","iopub.status.idle":"2024-02-24T11:05:18.460605Z","shell.execute_reply.started":"2024-02-24T11:05:18.056994Z","shell.execute_reply":"2024-02-24T11:05:18.459257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nHP_bef=data['HomePlanet'].isna().sum()\n\n# Decks A, B, C or T came from Europa\ndata.loc[(data['HomePlanet'].isna()) & (data['Cabin_deck'].isin(['A', 'B', 'C', 'T'])), 'HomePlanet']='Europa'\n\n# Deck G came from Earth\ndata.loc[(data['HomePlanet'].isna()) & (data['Cabin_deck']=='G'), 'HomePlanet']='Earth'\n\n# Print number of missing values left\nprint('#HomePlanet missing values before:',HP_bef)\nprint('#HomePlanet missing values after:',data['HomePlanet'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.462044Z","iopub.execute_input":"2024-02-24T11:05:18.462815Z","iopub.status.idle":"2024-02-24T11:05:18.477093Z","shell.execute_reply.started":"2024-02-24T11:05:18.462775Z","shell.execute_reply":"2024-02-24T11:05:18.475938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Surname and HomePlanet - Using Surname\nSHP_gb=data.groupby(['Surname','HomePlanet'])['HomePlanet'].size().unstack().fillna(0)\n\n# Countplot of unique values\nplt.figure(figsize=(10,4))\nsns.countplot((SHP_gb>0).sum(axis=1))\nplt.title('Number of unique planets per surname') \n#Everyone with the same surname comes from the same home planet.","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.478670Z","iopub.execute_input":"2024-02-24T11:05:18.479134Z","iopub.status.idle":"2024-02-24T11:05:18.690065Z","shell.execute_reply.started":"2024-02-24T11:05:18.479098Z","shell.execute_reply":"2024-02-24T11:05:18.688837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SHP_gb","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.691057Z","iopub.execute_input":"2024-02-24T11:05:18.691356Z","iopub.status.idle":"2024-02-24T11:05:18.709236Z","shell.execute_reply.started":"2024-02-24T11:05:18.691333Z","shell.execute_reply":"2024-02-24T11:05:18.708120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nHP_bef=data['HomePlanet'].isna().sum()\n\n\n# SHP_index=data[data['HomePlanet'].isna()][(data[data['HomePlanet'].isna()]['Surname']).isin(SHP_gb.index)].index\n\n# # Fill corresponding missing values\n# data.loc[SHP_index,'HomePlanet']=data.iloc[SHP_index,:]['Surname'].map(lambda x: SHP_gb.idxmax(axis=1)[x])\n\n#Simplified Code\n# Passengers with missing HomePlanet and in a family with known HomePlanet\nSHP_index = data[data['HomePlanet'].isna() & data['Surname'].isin(SHP_gb.index)].index\n#Fill corresponding missing values\ndata.loc[SHP_index, 'HomePlanet'] = data.loc[SHP_index, 'Surname'].replace(SHP_gb.idxmax(axis=1))\n\n# Print number of missing values left\nprint('#HomePlanet missing values before:',HP_bef)\nprint('#HomePlanet missing values after:',data['HomePlanet'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.710365Z","iopub.execute_input":"2024-02-24T11:05:18.710688Z","iopub.status.idle":"2024-02-24T11:05:18.814663Z","shell.execute_reply.started":"2024-02-24T11:05:18.710661Z","shell.execute_reply":"2024-02-24T11:05:18.813926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only 10 HomePlanet missing values left - let's look at them\ndata[data['HomePlanet'].isna()][['PassengerId','HomePlanet','Destination']]\n\n#Everyone left is heading towards TRAPPIST-1e. So let's look at the joint distribution of HomePlanet and Destination.","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.816113Z","iopub.execute_input":"2024-02-24T11:05:18.816469Z","iopub.status.idle":"2024-02-24T11:05:18.830318Z","shell.execute_reply.started":"2024-02-24T11:05:18.816421Z","shell.execute_reply":"2024-02-24T11:05:18.829057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using Destination\n\n#HomePlanet and Destination\n# Joint distribution of HomePlanet and Destination\nHPD_gb=data.groupby(['HomePlanet','Destination'])['Destination'].count().unstack().fillna(0)\n\n# Heatmap of missing values\nplt.figure(figsize=(10,4))\nsns.heatmap(HPD_gb.T, annot=True, fmt='g', cmap='coolwarm')\n\"\"\"\nMost people heading towards TRAPPIST-1e came from Earth so it makes sense to guess they came from there. \n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:18.831779Z","iopub.execute_input":"2024-02-24T11:05:18.832378Z","iopub.status.idle":"2024-02-24T11:05:19.159174Z","shell.execute_reply.started":"2024-02-24T11:05:18.832337Z","shell.execute_reply":"2024-02-24T11:05:19.158063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nHP_bef=data['HomePlanet'].isna().sum()\n\n# Fill remaining HomePlanet missing values with Earth (if not on deck D) or Mars (if on Deck D)\ndata.loc[(data['HomePlanet'].isna()) & ~(data['Cabin_deck']=='D'), 'HomePlanet']='Earth'\ndata.loc[(data['HomePlanet'].isna()) & (data['Cabin_deck']=='D'), 'HomePlanet']='Mars'\n\n# Print number of missing values left\nprint('#HomePlanet missing values before:',HP_bef)\nprint('#HomePlanet missing values after:',data['HomePlanet'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.160624Z","iopub.execute_input":"2024-02-24T11:05:19.161743Z","iopub.status.idle":"2024-02-24T11:05:19.178133Z","shell.execute_reply.started":"2024-02-24T11:05:19.161704Z","shell.execute_reply":"2024-02-24T11:05:19.176778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['HomePlanet'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.179979Z","iopub.execute_input":"2024-02-24T11:05:19.180608Z","iopub.status.idle":"2024-02-24T11:05:19.190922Z","shell.execute_reply.started":"2024-02-24T11:05:19.180579Z","shell.execute_reply":"2024-02-24T11:05:19.189474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.192311Z","iopub.execute_input":"2024-02-24T11:05:19.192690Z","iopub.status.idle":"2024-02-24T11:05:19.223589Z","shell.execute_reply.started":"2024-02-24T11:05:19.192643Z","shell.execute_reply":"2024-02-24T11:05:19.222452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()\n\n#Long way to go to handle missing values","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.225583Z","iopub.execute_input":"2024-02-24T11:05:19.226185Z","iopub.status.idle":"2024-02-24T11:05:19.242087Z","shell.execute_reply.started":"2024-02-24T11:05:19.226157Z","shell.execute_reply":"2024-02-24T11:05:19.241058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new column 'Missing_Destination' to indicate missing values\ntrain['Missing_Destination'] = train['Destination'].isna()\n\n# Plot countplot with hue='Missing_Destination'\nsns.countplot(data=train, x='Destination', hue='Missing_Destination')\n\n# Display the percentage on top of each bar\ntotal = len(train['Destination'].dropna())  # Total non-missing values\nfor p in plt.gca().patches:\n    height = p.get_height() if not pd.isna(p.get_height()) else 0\n    plt.text(p.get_x() + p.get_width() / 2., height + 0.05,\n             f'{height/total:.1%}', ha='center', va='bottom')\n\n# Show the plot\nplt.show()\ntrain.drop(['Missing_Destination'],axis=1,inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.243529Z","iopub.execute_input":"2024-02-24T11:05:19.244068Z","iopub.status.idle":"2024-02-24T11:05:19.510390Z","shell.execute_reply.started":"2024-02-24T11:05:19.244030Z","shell.execute_reply":"2024-02-24T11:05:19.509386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#majority of values belong to trappist-1e\n\n#Using Destination\n\n#HomePlanet and Destination\n# Joint distribution of HomePlanet and Destination\nHPD_gb=data.groupby(['HomePlanet','Destination'])['Destination'].count().unstack().fillna(0)\n\n# Heatmap of missing values\nplt.figure(figsize=(10,4))\nsns.heatmap(HPD_gb.T, annot=True, fmt='g', cmap='coolwarm')\n\"\"\"\nMost people heading towards TRAPPIST-1e came from Earth so it makes sense to guess they came from there. \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.511652Z","iopub.execute_input":"2024-02-24T11:05:19.511978Z","iopub.status.idle":"2024-02-24T11:05:19.831856Z","shell.execute_reply.started":"2024-02-24T11:05:19.511950Z","shell.execute_reply":"2024-02-24T11:05:19.830688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"des_na = train[train['Destination'].isna()]\nsns.countplot(data = des_na, x='HomePlanet')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:19.833246Z","iopub.execute_input":"2024-02-24T11:05:19.833665Z","iopub.status.idle":"2024-02-24T11:05:20.077734Z","shell.execute_reply.started":"2024-02-24T11:05:19.833629Z","shell.execute_reply":"2024-02-24T11:05:20.076554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Des_na_sum=data['Destination'].isna().sum()\nDes_na_sum","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.079206Z","iopub.execute_input":"2024-02-24T11:05:20.079620Z","iopub.status.idle":"2024-02-24T11:05:20.086994Z","shell.execute_reply.started":"2024-02-24T11:05:20.079582Z","shell.execute_reply":"2024-02-24T11:05:20.085982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Surname and HomePlanet - Using Surname\nDES_gb=data.groupby(['HomePlanet','Destination'])['Destination'].count().unstack().fillna(0)\nDES_gb","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.088166Z","iopub.execute_input":"2024-02-24T11:05:20.088461Z","iopub.status.idle":"2024-02-24T11:05:20.108001Z","shell.execute_reply.started":"2024-02-24T11:05:20.088436Z","shell.execute_reply":"2024-02-24T11:05:20.107245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nDes_na_sum=data['Destination'].isna().sum()\nDES_gb=data.groupby(['HomePlanet','Destination'])['Destination'].count().unstack().fillna(0)\n\n# Passengers with missing Destination and in a Homeplanet\nDHP_index = data[data['Destination'].isna() & data['HomePlanet'].isin(DES_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[DHP_index, 'Destination'] = data.loc[DHP_index, 'HomePlanet'].replace(DES_gb.idxmax(axis=1))\n\n# Print number of missing values left\nprint('#Destination missing values before:',Des_na_sum)\nprint('#Destination missing values after:',data['Destination'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.109225Z","iopub.execute_input":"2024-02-24T11:05:20.110234Z","iopub.status.idle":"2024-02-24T11:05:20.130706Z","shell.execute_reply.started":"2024-02-24T11:05:20.110202Z","shell.execute_reply":"2024-02-24T11:05:20.129352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Destination'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.132275Z","iopub.execute_input":"2024-02-24T11:05:20.133443Z","iopub.status.idle":"2024-02-24T11:05:20.142601Z","shell.execute_reply.started":"2024-02-24T11:05:20.133403Z","shell.execute_reply":"2024-02-24T11:05:20.141456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Destination\n# # Missing values before\n# D_bef=data['Destination'].isna().sum()\n\n# # Fill missing Destination values with mode\n# data.loc[(data['Destination'].isna()), 'Destination']='TRAPPIST-1e'\n\n# # Print number of missing values left\n# print('#Destination missing values before:',D_bef)\n# print('#Destination missing values after:',data['Destination'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.143933Z","iopub.execute_input":"2024-02-24T11:05:20.144245Z","iopub.status.idle":"2024-02-24T11:05:20.150408Z","shell.execute_reply.started":"2024-02-24T11:05:20.144220Z","shell.execute_reply":"2024-02-24T11:05:20.149340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Group and Surname\nGSN_gb=data[data['Group_size']>1].groupby(['Group','Surname'])['Surname'].size().unstack().fillna(0)\n\"\"\"The majority (83%) of groups contain only 1 family. \nSo let's fill missing surnames according to the majority surname in that group\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.152080Z","iopub.execute_input":"2024-02-24T11:05:20.152492Z","iopub.status.idle":"2024-02-24T11:05:20.215776Z","shell.execute_reply.started":"2024-02-24T11:05:20.152457Z","shell.execute_reply":"2024-02-24T11:05:20.214666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GSN_gb","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:20.217155Z","iopub.execute_input":"2024-02-24T11:05:20.218231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nSN_bef=data['Surname'].isna().sum()\n\n# Passengers with missing Surname and in a group with known majority Surname\nGSN_index=data[data['Surname'].isna()][(data[data['Surname'].isna()]['Group']).isin(GSN_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[GSN_index,'Surname']=data.iloc[GSN_index,:]['Group'].map(lambda x: GSN_gb.idxmax(axis=1)[x])\n\n# Print number of missing values left\nprint('#Surname missing values before:',SN_bef)\nprint('#Surname missing values after:',data['Surname'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:22.230583Z","iopub.execute_input":"2024-02-24T11:05:22.230902Z","iopub.status.idle":"2024-02-24T11:05:23.275522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace NaN's with outliers (so we can use map)\ndata['Surname'].fillna('Unknown', inplace=True)\n\n# Update family size feature\ndata['Family_size']=data['Surname'].map(lambda x: data['Surname'].value_counts()[x])\n\n# Put NaN's back in place of outliers\ndata.loc[data['Surname']=='Unknown','Surname']=np.nan\n\n# Say unknown surname means no family\ndata.loc[data['Family_size']>100,'Family_size']=0","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:23.277112Z","iopub.execute_input":"2024-02-24T11:05:23.277850Z","iopub.status.idle":"2024-02-24T11:05:54.560552Z","shell.execute_reply.started":"2024-02-24T11:05:23.277814Z","shell.execute_reply":"2024-02-24T11:05:54.559379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Surname'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:54.561801Z","iopub.execute_input":"2024-02-24T11:05:54.562120Z","iopub.status.idle":"2024-02-24T11:05:54.570206Z","shell.execute_reply.started":"2024-02-24T11:05:54.562095Z","shell.execute_reply":"2024-02-24T11:05:54.569183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(['HomePlanet','Surname'])['Surname'].count().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:54.571828Z","iopub.execute_input":"2024-02-24T11:05:54.572181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using HomePlanet to fill Surname\nSurname_na_sum=data['Surname'].isna().sum()\n\nSUR_gb=data.groupby(['HomePlanet','Surname'])['Surname'].count().unstack().fillna(0)\n\n# Passengers with missing Destination and in a Homeplanet\nSURHP_index = data[data['Surname'].isna() & data['HomePlanet'].isin(SUR_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[SURHP_index, 'Surname'] = data.loc[SURHP_index, 'HomePlanet'].replace(SUR_gb.idxmax(axis=1))\n\n# Print number of missing values left\nprint('#Destination missing values before:',Surname_na_sum)\nprint('#Destination missing values after:',data['Surname'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.341084Z","iopub.execute_input":"2024-02-24T11:05:56.341599Z","iopub.status.idle":"2024-02-24T11:05:56.368481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.369744Z","iopub.execute_input":"2024-02-24T11:05:56.370598Z","iopub.status.idle":"2024-02-24T11:05:56.386576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Group and Cabin features - all have 299 values missing\n#We just want group_size > 1 ie 2-8 to handle in between missing values\nGCD_gb=data[data['Group_size']>1].groupby(['Group','Cabin_deck'])['Cabin_deck'].count().unstack().fillna(0)\nGCN_gb=data[data['Group_size']>1].groupby(['Group','Cabin_number'])['Cabin_number'].count().unstack().fillna(0)\nGCS_gb=data[data['Group_size']>1].groupby(['Group','Cabin_side'])['Cabin_side'].count().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.387851Z","iopub.execute_input":"2024-02-24T11:05:56.388177Z","iopub.status.idle":"2024-02-24T11:05:56.448989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['Group_size']>1].groupby(['Group','Cabin_side'])['Cabin_side'].count().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.450328Z","iopub.execute_input":"2024-02-24T11:05:56.450675Z","iopub.status.idle":"2024-02-24T11:05:56.472613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nCS_bef=data['Cabin_side'].isna().sum()\n\n# Passengers with missing Cabin side and in a group with known Cabin side\nGCS_index=  data.loc[data['Cabin_side'].isna() & data['Group'].isin(GCS_gb.index),:].index\n# Fill corresponding missing values\ndata.loc[GCS_index,'Cabin_side']= data.iloc[GCS_index,:]['Group'].map(lambda x: GCS_gb.idxmax(axis=1)[x])\n\n# Print number of missing values left\nprint('#Cabin_side missing values before:',CS_bef)\nprint('#Cabin_side missing values after:',data['Cabin_side'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.474560Z","iopub.execute_input":"2024-02-24T11:05:56.475198Z","iopub.status.idle":"2024-02-24T11:05:56.609620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCS_gb = data[data['Group_size']>1].groupby(['Surname','Cabin_side'])['Cabin_side'].size().unstack().fillna(0)\nSCS_gb\n#Yorkland has 2.0 and 5.0 in P and S respectively meaning same surname are in 2 different cabin_side","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.610622Z","iopub.execute_input":"2024-02-24T11:05:56.610936Z","iopub.status.idle":"2024-02-24T11:05:56.633559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCS_gb['P']/(SCS_gb['P']+SCS_gb['S'])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.634853Z","iopub.execute_input":"2024-02-24T11:05:56.635169Z","iopub.status.idle":"2024-02-24T11:05:56.644944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution of Surname and Cabin side\nSCS_gb=data[data['Group_size']>1].groupby(['Surname','Cabin_side'])['Cabin_side'].size().unstack().fillna(0)\n\n# Ratio of sides - It states that how much % of family are in same cabin side. \n# Few points in between 0-1 suggest family having same name are in different Cabin_side\n    #1 plausible explaination is that though Surname is same, they are not family members ie same surname but no blood relation\nSCS_gb['Ratio']= SCS_gb['P']/(SCS_gb['P']+SCS_gb['S'])\n\n# Histogram of ratio\nplt.figure(figsize=(10,4))\nsns.histplot(SCS_gb['Ratio'], kde=True, binwidth=0.05)\nplt.title('Ratio of cabin side by Surname')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:56.646285Z","iopub.execute_input":"2024-02-24T11:05:56.646586Z","iopub.status.idle":"2024-02-24T11:05:57.073097Z","shell.execute_reply.started":"2024-02-24T11:05:56.646561Z","shell.execute_reply":"2024-02-24T11:05:57.071848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print proportion\nprint('Percentage of families all on the same cabin side:', 100*np.round((SCS_gb['Ratio'].isin([0,1])).sum()/len(SCS_gb),3),'%')\n\n# Another view of the same information\nSCS_gb.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.074365Z","iopub.execute_input":"2024-02-24T11:05:57.074690Z","iopub.status.idle":"2024-02-24T11:05:57.089250Z","shell.execute_reply.started":"2024-02-24T11:05:57.074664Z","shell.execute_reply":"2024-02-24T11:05:57.087915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This shows that families tend to be on the same cabin side (and 77% of families are entirely on the same side).\n# Missing values before\nCS_bef=data['Cabin_side'].isna().sum()\n\n# Drop ratio column\nSCS_gb.drop('Ratio', axis=1, inplace=True)\n\n# Passengers with missing Cabin side and in a family with known Cabin side\n# SCS_index=data[data['Cabin_side'].isna()][(data[data['Cabin_side'].isna()]['Surname']).isin(SCS_gb.index)].index\n\n# # Fill corresponding missing values\n# data.loc[SCS_index,'Cabin_side']=data.iloc[SCS_index,:]['Surname'].map(lambda x: SCS_gb.idxmax(axis=1)[x])\n\nSCS_index = data[data['Cabin_side'].isna() & data['Surname'].isin(SCS_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[SCS_index, 'Cabin_side'] = data.loc[SCS_index, 'Surname'].map(SCS_gb.idxmax(axis=1))\n\n\n# Drop surname (we don't need it anymore)\ndata.drop('Surname', axis=1, inplace=True)\n\n# Print number of missing values left\nprint('#Cabin_side missing values before:',CS_bef)\nprint('#Cabin_side missing values after:',data['Cabin_side'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.090816Z","iopub.execute_input":"2024-02-24T11:05:57.091254Z","iopub.status.idle":"2024-02-24T11:05:57.116356Z","shell.execute_reply.started":"2024-02-24T11:05:57.091217Z","shell.execute_reply":"2024-02-24T11:05:57.114813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(['HomePlanet','Cabin_side'])['Cabin_side'].count().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.117558Z","iopub.execute_input":"2024-02-24T11:05:57.117951Z","iopub.status.idle":"2024-02-24T11:05:57.134086Z","shell.execute_reply.started":"2024-02-24T11:05:57.117912Z","shell.execute_reply":"2024-02-24T11:05:57.132935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HPCS_gb = data.groupby(['HomePlanet','Cabin_side'])['Cabin_side'].count().unstack().fillna(0)\nCS_bef=data['Cabin_side'].isna().sum() #65\n\nHPCS_index = data[data['Cabin_side'].isna() & data['HomePlanet'].isin(HPCS_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[HPCS_index, 'Cabin_side'] = data.loc[HPCS_index, 'HomePlanet'].map(HPCS_gb.idxmax(axis=1))\n\n# Print number of missing values left\nprint('#Cabin_side missing values before:',CS_bef)\nprint('#Cabin_side missing values after:',data['Cabin_side'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.135418Z","iopub.execute_input":"2024-02-24T11:05:57.136402Z","iopub.status.idle":"2024-02-24T11:05:57.157952Z","shell.execute_reply.started":"2024-02-24T11:05:57.136365Z","shell.execute_reply":"2024-02-24T11:05:57.156727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Missing values before\n# CS_bef=data['Cabin_side'].isna().sum()\n\n# # Fill remaining missing values with outlier\n# data.loc[data['Cabin_side'].isna(),'Cabin_side']='Z'\n\n# # Print number of missing values left\n# print('#Cabin_side missing values before:',CS_bef)\n# print('#Cabin_side missing values after:',data['Cabin_side'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.160723Z","iopub.execute_input":"2024-02-24T11:05:57.161172Z","iopub.status.idle":"2024-02-24T11:05:57.166011Z","shell.execute_reply.started":"2024-02-24T11:05:57.161138Z","shell.execute_reply":"2024-02-24T11:05:57.164797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Cabin_deck'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.167571Z","iopub.execute_input":"2024-02-24T11:05:57.168009Z","iopub.status.idle":"2024-02-24T11:05:57.179955Z","shell.execute_reply.started":"2024-02-24T11:05:57.167970Z","shell.execute_reply":"2024-02-24T11:05:57.178684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nCD_bef=data['Cabin_deck'].isna().sum()\n\n# Passengers with missing Cabin deck and in a group with known majority Cabin deck\nGCD_index=data[data['Cabin_deck'].isna()][(data[data['Cabin_deck'].isna()]['Group']).isin(GCD_gb.index)].index\n\n# Fill corresponding missing values\ndata.loc[GCD_index,'Cabin_deck']=data.iloc[GCD_index,:]['Group'].map(lambda x: GCD_gb.idxmax(axis=1)[x])\n\n# Print number of missing values left\nprint('#Cabin_deck missing values before:',CD_bef)\nprint('#Cabin_deck missing values after:',data['Cabin_deck'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.181873Z","iopub.execute_input":"2024-02-24T11:05:57.182293Z","iopub.status.idle":"2024-02-24T11:05:57.328799Z","shell.execute_reply.started":"2024-02-24T11:05:57.182255Z","shell.execute_reply":"2024-02-24T11:05:57.327514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution\ndata.groupby(['HomePlanet','Destination','Solo','Cabin_deck'])['Cabin_deck'].size().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.330124Z","iopub.execute_input":"2024-02-24T11:05:57.330447Z","iopub.status.idle":"2024-02-24T11:05:57.362427Z","shell.execute_reply.started":"2024-02-24T11:05:57.330420Z","shell.execute_reply":"2024-02-24T11:05:57.361611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nCD_bef=data['Cabin_deck'].isna().sum()\n\n#Cabin_deck --> A,B,C,D,E,F,G,T\n# Fill missing values using the mode\nna_rows_CD=data.loc[data['Cabin_deck'].isna(),'Cabin_deck'].index\ndata.loc[data['Cabin_deck'].isna(),'Cabin_deck']=data.groupby(['HomePlanet','Destination','Solo'])['Cabin_deck'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))[na_rows_CD]\n\n# Print number of missing values left\nprint('#Cabin_deck missing values before:',CD_bef)\nprint('#Cabin_deck missing values after:',data['Cabin_deck'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.364198Z","iopub.execute_input":"2024-02-24T11:05:57.364608Z","iopub.status.idle":"2024-02-24T11:05:57.396859Z","shell.execute_reply.started":"2024-02-24T11:05:57.364568Z","shell.execute_reply":"2024-02-24T11:05:57.395819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a scatter plot\nscatter_plot = sns.scatterplot(\n    x=data['Cabin_number'],\n    y=data['Group'],\n    hue=data.loc[data['Cabin_number'].notnull(),'Cabin_deck'],\n    palette='tab10'\n)\n\n# Add legend\nscatter_plot.legend(title='Cabin_deck')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:57.398226Z","iopub.execute_input":"2024-02-24T11:05:57.398635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[(data['Cabin_number'].notnull()) & (data['Cabin_deck']=='A'),'Group']","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.374505Z","iopub.execute_input":"2024-02-24T11:05:58.374896Z","iopub.status.idle":"2024-02-24T11:05:58.386295Z","shell.execute_reply.started":"2024-02-24T11:05:58.374865Z","shell.execute_reply":"2024-02-24T11:05:58.384982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" data.loc[(data['Cabin_number'].isna()) & (data['Cabin_deck']==\"A\"),'Group']","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.387601Z","iopub.execute_input":"2024-02-24T11:05:58.388144Z","iopub.status.idle":"2024-02-24T11:05:58.399381Z","shell.execute_reply.started":"2024-02-24T11:05:58.388091Z","shell.execute_reply":"2024-02-24T11:05:58.398439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nCN_bef=data['Cabin_number'].isna().sum()\n\n# Extrapolate linear relationship on a deck by deck basis\nfor deck in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n    # Features and labels\n    X_CN= data.loc[(data['Cabin_number'].notnull()) & (data['Cabin_deck']==deck),'Group']\n    y_CN= data.loc[(data['Cabin_number'].notnull()) & (data['Cabin_deck']==deck),'Cabin_number']\n    \n    X_test_CN= data.loc[(data['Cabin_number'].isna()) & (data['Cabin_deck']==deck),'Group']\n\n    # Linear regression\n    lr= LinearRegression()\n    lr.fit(X_CN.values.reshape(-1, 1), y_CN)\n    preds_CN=lr.predict(X_test_CN.values.reshape(-1, 1))\n    \n    # Fill missing values with predictions\n    data.loc[(data['Cabin_number'].isna()) & (data['Cabin_deck']==deck),'Cabin_number']=preds_CN.astype(int)\n\n# Print number of missing values left\nprint('#Cabin_number missing values before:',CN_bef)\nprint('#Cabin_number missing values after:',data['Cabin_number'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.400829Z","iopub.execute_input":"2024-02-24T11:05:58.401464Z","iopub.status.idle":"2024-02-24T11:05:58.484838Z","shell.execute_reply.started":"2024-02-24T11:05:58.401433Z","shell.execute_reply":"2024-02-24T11:05:58.483804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.485975Z","iopub.execute_input":"2024-02-24T11:05:58.486306Z","iopub.status.idle":"2024-02-24T11:05:58.512750Z","shell.execute_reply.started":"2024-02-24T11:05:58.486278Z","shell.execute_reply":"2024-02-24T11:05:58.511568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode cabin regions\ndata['Cabin_region1']=(data['Cabin_number']<300).astype(int)\ndata['Cabin_region2']=((data['Cabin_number']>=300) & (data['Cabin_number']<600)).astype(int)\ndata['Cabin_region3']=((data['Cabin_number']>=600) & (data['Cabin_number']<900)).astype(int)\ndata['Cabin_region4']=((data['Cabin_number']>=900) & (data['Cabin_number']<1200)).astype(int)\ndata['Cabin_region5']=((data['Cabin_number']>=1200) & (data['Cabin_number']<1500)).astype(int)\ndata['Cabin_region6']=((data['Cabin_number']>=1500) & (data['Cabin_number']<1800)).astype(int)\ndata['Cabin_region7']=(data['Cabin_number']>=1800).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.514389Z","iopub.execute_input":"2024-02-24T11:05:58.514700Z","iopub.status.idle":"2024-02-24T11:05:58.528348Z","shell.execute_reply.started":"2024-02-24T11:05:58.514673Z","shell.execute_reply":"2024-02-24T11:05:58.527382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nV_bef=data['VIP'].isna().sum()\n\n# Fill missing values with mode\ndata.loc[data['VIP'].isna(),'VIP']=False\n\n# Print number of missing values left\nprint('#VIP missing values before:',V_bef)\nprint('#VIP missing values after:',data['VIP'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.529557Z","iopub.execute_input":"2024-02-24T11:05:58.529946Z","iopub.status.idle":"2024-02-24T11:05:58.542872Z","shell.execute_reply.started":"2024-02-24T11:05:58.529920Z","shell.execute_reply":"2024-02-24T11:05:58.541912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.543715Z","iopub.execute_input":"2024-02-24T11:05:58.544045Z","iopub.status.idle":"2024-02-24T11:05:58.561727Z","shell.execute_reply.started":"2024-02-24T11:05:58.544014Z","shell.execute_reply":"2024-02-24T11:05:58.560799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Age varies across many features like HomePlanet, group size, expenditure and cabin deck, \n#so we will impute missing values according to the median of these subgroups.\n\n# Joint distribution\ndata.groupby(['HomePlanet','No_spending','Solo','Cabin_deck'])['Age'].median().unstack().fillna(0)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.563338Z","iopub.execute_input":"2024-02-24T11:05:58.564460Z","iopub.status.idle":"2024-02-24T11:05:58.595544Z","shell.execute_reply.started":"2024-02-24T11:05:58.564416Z","shell.execute_reply":"2024-02-24T11:05:58.594701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nA_bef=data[exp_feats].isna().sum().sum()\n\n# Fill missing values using the median\nna_rows_A=data.loc[data['Age'].isna(),'Age'].index\ndata.loc[data['Age'].isna(),'Age']=data.groupby(['HomePlanet','No_spending','Solo','Cabin_deck'])['Age'].transform(lambda x: x.fillna(x.median()))[na_rows_A]\n\n# Print number of missing values left\nprint('#Age missing values before:',A_bef)\nprint('#Age missing values after:',data['Age'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.596776Z","iopub.execute_input":"2024-02-24T11:05:58.597089Z","iopub.status.idle":"2024-02-24T11:05:58.633173Z","shell.execute_reply.started":"2024-02-24T11:05:58.597061Z","shell.execute_reply":"2024-02-24T11:05:58.632190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update age group feature\ndata.loc[data['Age']<=12,'Age_group']='Age_0-12'\ndata.loc[(data['Age']>12) & (data['Age']<18),'Age_group']='Age_13-17'\ndata.loc[(data['Age']>=18) & (data['Age']<=25),'Age_group']='Age_18-25'\ndata.loc[(data['Age']>25) & (data['Age']<=30),'Age_group']='Age_26-30'\ndata.loc[(data['Age']>30) & (data['Age']<=50),'Age_group']='Age_31-50'\ndata.loc[data['Age']>50,'Age_group']='Age_51+'","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.634354Z","iopub.execute_input":"2024-02-24T11:05:58.634730Z","iopub.status.idle":"2024-02-24T11:05:58.646836Z","shell.execute_reply.started":"2024-02-24T11:05:58.634704Z","shell.execute_reply":"2024-02-24T11:05:58.645809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joint distribution\ndata.groupby(['No_spending','CryoSleep'])['CryoSleep'].size().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.647964Z","iopub.execute_input":"2024-02-24T11:05:58.648296Z","iopub.status.idle":"2024-02-24T11:05:58.663520Z","shell.execute_reply.started":"2024-02-24T11:05:58.648269Z","shell.execute_reply":"2024-02-24T11:05:58.662427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nCSL_bef=data['CryoSleep'].isna().sum()\n\n# Fill missing values using the mode\nna_rows_CSL=data.loc[data['CryoSleep'].isna(),'CryoSleep'].index\ndata.loc[data['CryoSleep'].isna(),'CryoSleep']=data.groupby(['No_spending'])['CryoSleep'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))[na_rows_CSL]\n\n# Print number of missing values left\nprint('#CryoSleep missing values before:',CSL_bef)\nprint('#CryoSleep missing values after:',data['CryoSleep'].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.665189Z","iopub.execute_input":"2024-02-24T11:05:58.665592Z","iopub.status.idle":"2024-02-24T11:05:58.685036Z","shell.execute_reply.started":"2024-02-24T11:05:58.665563Z","shell.execute_reply":"2024-02-24T11:05:58.684126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This one makes a lot of sense. We don't expect people in CryoSleep to be able to spend anything.\nprint('Maximum expenditure of passengers in CryoSleep:',data.loc[data['CryoSleep']==True,exp_feats].sum(axis=1).max())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.686318Z","iopub.execute_input":"2024-02-24T11:05:58.686616Z","iopub.status.idle":"2024-02-24T11:05:58.697355Z","shell.execute_reply.started":"2024-02-24T11:05:58.686592Z","shell.execute_reply":"2024-02-24T11:05:58.696153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nE_bef=data[exp_feats].isna().sum().sum()\n\n# CryoSleep has no expenditure\nfor col in exp_feats:\n    data.loc[(data[col].isna()) & (data['CryoSleep']==True), col]=0\n\n# Print number of missing values left\nprint('#Expenditure missing values before:',E_bef)\nprint('#Expenditure missing values after:',data[exp_feats].isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.698790Z","iopub.execute_input":"2024-02-24T11:05:58.699119Z","iopub.status.idle":"2024-02-24T11:05:58.720314Z","shell.execute_reply.started":"2024-02-24T11:05:58.699093Z","shell.execute_reply":"2024-02-24T11:05:58.719486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Expenditure'].mean(),  data['Expenditure'].median(),\n#This states that those not in cryo sleep are spending way too much causing outliers","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.721518Z","iopub.execute_input":"2024-02-24T11:05:58.722528Z","iopub.status.idle":"2024-02-24T11:05:58.730078Z","shell.execute_reply.started":"2024-02-24T11:05:58.722489Z","shell.execute_reply":"2024-02-24T11:05:58.729043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data = data, x= 'Expenditure',hue='CryoSleep')\nplt.title('Expenditure BoxPlot')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:58.731853Z","iopub.execute_input":"2024-02-24T11:05:58.732444Z","iopub.status.idle":"2024-02-24T11:05:59.025946Z","shell.execute_reply.started":"2024-02-24T11:05:58.732406Z","shell.execute_reply":"2024-02-24T11:05:59.024893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nExpenditure varies across many features but we will only impute missing values using HomePlanet, \nSolo and Age group to prevent overfitting. We will also use the mean instead of the median because a \nlarge proportion of passengers don't spend anything and median usually comes out as 0. \nNote how under 12 age don't spend anything suggesting they have no spending power which is obvious.\n\"\"\"\n\n# Joint distribution\ndata.groupby(['HomePlanet','Solo','Age_group'])['Expenditure'].mean().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.027434Z","iopub.execute_input":"2024-02-24T11:05:59.028085Z","iopub.status.idle":"2024-02-24T11:05:59.051316Z","shell.execute_reply.started":"2024-02-24T11:05:59.028052Z","shell.execute_reply":"2024-02-24T11:05:59.050528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values before\nE_bef=data[exp_feats].isna().sum().sum()\n\n# Fill remaining missing values using the median\nfor col in exp_feats:\n    na_rows=data.loc[data[col].isna(),col].index\n    data.loc[data[col].isna(),col]=data.groupby(['HomePlanet','Solo','Age_group'])[col].transform(lambda x: x.fillna(x.mean()))[na_rows]\n    \n# Print number of missing values left\nprint('#Expenditure missing values before:',E_bef)\nprint('#Expenditure missing values after:',data[exp_feats].isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.052344Z","iopub.execute_input":"2024-02-24T11:05:59.053268Z","iopub.status.idle":"2024-02-24T11:05:59.150475Z","shell.execute_reply.started":"2024-02-24T11:05:59.053238Z","shell.execute_reply":"2024-02-24T11:05:59.149323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update expenditure and no_spending\ndata['Expenditure']=data[exp_feats].sum(axis=1)\ndata['No_spending']=(data['Expenditure']==0).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.151864Z","iopub.execute_input":"2024-02-24T11:05:59.152348Z","iopub.status.idle":"2024-02-24T11:05:59.163462Z","shell.execute_reply.started":"2024-02-24T11:05:59.152311Z","shell.execute_reply":"2024-02-24T11:05:59.162275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.164787Z","iopub.execute_input":"2024-02-24T11:05:59.165169Z","iopub.status.idle":"2024-02-24T11:05:59.180269Z","shell.execute_reply.started":"2024-02-24T11:05:59.165140Z","shell.execute_reply":"2024-02-24T11:05:59.179212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = LabelEncoder()\ndata['HomePlanet'] = label.fit_transform(data['HomePlanet'])\ndata['CryoSleep'] = label.fit_transform(data['CryoSleep'])\ndata['Destination'] = label.fit_transform(data['Destination'])\ndata['VIP'] = label.fit_transform(data['VIP'])\ndata['Age_group'] = label.fit_transform(data['Age_group'])\ndata['Cabin_deck'] = label.fit_transform(data['Cabin_deck'])\ndata['Cabin_side'] = label.fit_transform(data['Cabin_side'])","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.181581Z","iopub.execute_input":"2024-02-24T11:05:59.181972Z","iopub.status.idle":"2024-02-24T11:05:59.213181Z","shell.execute_reply.started":"2024-02-24T11:05:59.181941Z","shell.execute_reply":"2024-02-24T11:05:59.211729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:51:48.756685Z","iopub.execute_input":"2024-02-24T12:51:48.757147Z","iopub.status.idle":"2024-02-24T12:51:48.791866Z","shell.execute_reply.started":"2024-02-24T12:51:48.757112Z","shell.execute_reply":"2024-02-24T12:51:48.790609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing\n# Train and test\nX=data[data['PassengerId'].isin(train['PassengerId'].values)].copy()\nX_test=data[data['PassengerId'].isin(test['PassengerId'].values)].copy()\n\n# Drop qualitative/redundant/collinear/high cardinality features\nX.drop(['PassengerId', 'Group', 'Age_group', 'Cabin_number'], axis=1, inplace=True)\nX_test.drop(['PassengerId', 'Group', 'Age_group', 'Cabin_number'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.256604Z","iopub.execute_input":"2024-02-24T11:05:59.257293Z","iopub.status.idle":"2024-02-24T11:05:59.277066Z","shell.execute_reply.started":"2024-02-24T11:05:59.257263Z","shell.execute_reply":"2024-02-24T11:05:59.276104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X), len(y)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.278222Z","iopub.execute_input":"2024-02-24T11:05:59.279870Z","iopub.status.idle":"2024-02-24T11:05:59.286084Z","shell.execute_reply.started":"2024-02-24T11:05:59.279840Z","shell.execute_reply":"2024-02-24T11:05:59.284895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-validation split\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,stratify=y,train_size=0.8,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:05:59.287211Z","iopub.execute_input":"2024-02-24T11:05:59.287506Z","iopub.status.idle":"2024-02-24T11:05:59.302451Z","shell.execute_reply.started":"2024-02-24T11:05:59.287480Z","shell.execute_reply":"2024-02-24T11:05:59.301130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modelling\n\n# Put models in a dictionary\nmodels = {\"KNN\": KNeighborsClassifier(),\n          \"Logistic Regression\": LogisticRegression(), \n          \"Random Forest\": RandomForestClassifier()}\n\n# Create function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    # Random seed for reproducible results\n    np.random.seed(42)\n    # Make a list to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(X_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:44:42.506044Z","iopub.execute_input":"2024-02-24T06:44:42.506468Z","iopub.status.idle":"2024-02-24T06:44:42.514418Z","shell.execute_reply.started":"2024-02-24T06:44:42.506434Z","shell.execute_reply":"2024-02-24T06:44:42.513047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_scores = fit_and_score(models=models,\n                             X_train=X_train,\n                             X_test=X_valid,\n                             y_train=y_train,\n                             y_test=y_valid)\nmodel_scores","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:45:15.243291Z","iopub.execute_input":"2024-02-24T06:45:15.243701Z","iopub.status.idle":"2024-02-24T06:45:16.844354Z","shell.execute_reply.started":"2024-02-24T06:45:15.243667Z","shell.execute_reply":"2024-02-24T06:45:16.843485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Comparison\nmodel_compare = pd.DataFrame(model_scores, index=['accuracy'])\nmodel_compare.T.plot.bar();","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:55:06.734496Z","iopub.execute_input":"2024-02-24T06:55:06.734907Z","iopub.status.idle":"2024-02-24T06:55:07.043429Z","shell.execute_reply.started":"2024-02-24T06:55:06.734877Z","shell.execute_reply":"2024-02-24T06:55:07.042457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHyperparameter tuning - Each model you use has a series of dials you can turn to dictate how they perform. Changing these values may increase or decrease model performance.\nFeature importance - If there are a large amount of features we're using to make predictions, do some have more importance than others? For example, for predicting heart disease, which is more important, sex or age?\nConfusion matrix - Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagnol line).\nCross-validation - Splits your dataset into multiple parts and train and tests your model on each part and evaluates performance as an average.\nPrecision - Proportion of true positives over total number of samples. Higher precision leads to less false positives.\nRecall - Proportion of true positives over total number of true positives and false negatives. Higher recall leads to less false negatives.\nF1 score - Combines precision and recall into one metric. 1 is best, 0 is worst.\nClassification report - Sklearn has a built-in function called classification_report() which returns some of the main classification metrics such as precision, recall and f1-score.\nROC Curve - Receiver Operating Characterisitc is a plot of true positive rate versus false positive rate.\nArea Under Curve (AUC) - The area underneath the ROC curve. A perfect model achieves a score of 1.0.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-24T06:56:53.970309Z","iopub.execute_input":"2024-02-24T06:56:53.970717Z","iopub.status.idle":"2024-02-24T06:56:53.980478Z","shell.execute_reply.started":"2024-02-24T06:56:53.970688Z","shell.execute_reply":"2024-02-24T06:56:53.979376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using RandomizedSearchCV on Logistic Regression and Random Forest","metadata":{"execution":{"iopub.status.busy":"2024-02-24T07:08:15.664452Z","iopub.execute_input":"2024-02-24T07:08:15.664889Z","iopub.status.idle":"2024-02-24T07:08:15.670994Z","shell.execute_reply.started":"2024-02-24T07:08:15.664856Z","shell.execute_reply":"2024-02-24T07:08:15.669779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup random seed\n\n# Different LogisticRegression hyperparameters\nlog_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n                \"solver\": [\"liblinear\"], \n                'penalty': ['l1','l2'],\n                'max_iter': [50, 100, 150]\n               }\nnp.random.seed(42)\n\n# Setup random hyperparameter search for LogisticRegression\nrs_log_reg = RandomizedSearchCV(LogisticRegression(),\n                                param_distributions=log_reg_grid,\n                                cv=5,\n                                n_iter=20,\n                                verbose=True)\n\n# Fit random hyperparameter search model\nrs_log_reg.fit(X_train, y_train)\nlr_bp = rs_log_reg.best_params_\nprint(lr_bp) #{'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 0.08858667904100823}\nrs_log_reg.score(X_valid, y_valid) #'Logistic Regression': 0.7843588269120184 earlier","metadata":{"execution":{"iopub.status.busy":"2024-02-24T07:10:12.163241Z","iopub.execute_input":"2024-02-24T07:10:12.163696Z","iopub.status.idle":"2024-02-24T07:10:22.964957Z","shell.execute_reply.started":"2024-02-24T07:10:12.163664Z","shell.execute_reply":"2024-02-24T07:10:22.963563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Different RandomForestClassifier hyperparameters\nrf_grid = {\"n_estimators\": [50, 100, 150, 200, 250, 300],\n           \"max_depth\": [4, 6, 8, 10, 12],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2)}\n\n\n# Setup random seed\nnp.random.seed(42)\n\n# Setup random hyperparameter search for RandomForestClassifier\nrs_rf = RandomizedSearchCV(RandomForestClassifier(),\n                           param_distributions=rf_grid,\n                           cv=5,\n                           n_iter=20,\n                           verbose=True)\n\n# Fit random hyperparameter search model\nrs_rf.fit(X_train, y_train) #{'n_estimators': 300, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 10}\nrf_bp = rs_rf.best_params_\nprint(rf_bp)\nrs_rf.score(X_valid, y_valid) #'Random Forest': 0.8067855089131685","metadata":{"execution":{"iopub.status.busy":"2024-02-24T07:20:38.735361Z","iopub.execute_input":"2024-02-24T07:20:38.735770Z","iopub.status.idle":"2024-02-24T07:22:34.531086Z","shell.execute_reply.started":"2024-02-24T07:20:38.735742Z","shell.execute_reply":"2024-02-24T07:22:34.529985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check best hyperparameters\nrs_rf.best_params_","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:09:12.117026Z","iopub.execute_input":"2024-02-24T09:09:12.117462Z","iopub.status.idle":"2024-02-24T09:09:12.129558Z","shell.execute_reply.started":"2024-02-24T09:09:12.117430Z","shell.execute_reply":"2024-02-24T09:09:12.128138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GridSearchCV will take a long time \n#Evaluating a classification model, beyond accuracy\n#Using default RandomForest with oob_score\n\nmodel1 = RandomForestClassifier(oob_score=True)\nmodel1.fit(X_train,y_train)\nmodel1.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:15:00.709559Z","iopub.execute_input":"2024-02-24T09:15:00.710027Z","iopub.status.idle":"2024-02-24T09:15:02.378955Z","shell.execute_reply.started":"2024-02-24T09:15:00.709984Z","shell.execute_reply":"2024-02-24T09:15:02.377802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make preidctions on test data\ny_preds = model1.predict(X_valid)\n\n#Using ROC Curve and AUC Scores\nfrom sklearn.metrics import RocCurveDisplay \n\nRocCurveDisplay.from_estimator(estimator=model1, X=X_valid, y=y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:15:06.134420Z","iopub.execute_input":"2024-02-24T09:15:06.134791Z","iopub.status.idle":"2024-02-24T09:15:06.617098Z","shell.execute_reply.started":"2024-02-24T09:15:06.134763Z","shell.execute_reply":"2024-02-24T09:15:06.615353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting Confusion matrix\n\nsns.set(font_scale=1.5) # Increase font size\n\ndef plot_conf_mat(y_valid, y_preds):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3, 3))\n    ax = sns.heatmap(confusion_matrix(y_valid, y_preds),\n                     annot=True, # Annotate the boxes\n                      fmt='d',\n                     cbar=False)\n    plt.xlabel(\"true label\")\n    plt.ylabel(\"predicted label\")\n    \nplot_conf_mat(y_valid, y_preds)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:15:11.531158Z","iopub.execute_input":"2024-02-24T09:15:11.532362Z","iopub.status.idle":"2024-02-24T09:15:11.700633Z","shell.execute_reply.started":"2024-02-24T09:15:11.532314Z","shell.execute_reply":"2024-02-24T09:15:11.699335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.oob_score_  #79% of time it classifiers the data properly on unseen data","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:15:25.251165Z","iopub.execute_input":"2024-02-24T09:15:25.251565Z","iopub.status.idle":"2024-02-24T09:15:25.258513Z","shell.execute_reply.started":"2024-02-24T09:15:25.251535Z","shell.execute_reply":"2024-02-24T09:15:25.257286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Classification report\n# Show classification report\n\"\"\"\nPrecision - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\nRecall - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\nF1 score - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\nSupport - The number of samples each metric was calculated on.\nAccuracy - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\nMacro avg - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn’t class imbalance into effort, so if you do have class imbalances, pay attention to this metric.\nWeighted avg - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. will give a high value when one class out performs another due to having more samples).\n\n\"\"\"\nprint(classification_report(y_valid, y_preds))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:04:47.388337Z","iopub.execute_input":"2024-02-24T09:04:47.388727Z","iopub.status.idle":"2024-02-24T09:04:47.408195Z","shell.execute_reply.started":"2024-02-24T09:04:47.388698Z","shell.execute_reply":"2024-02-24T09:04:47.406999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.get_params() #","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:08:31.753240Z","iopub.execute_input":"2024-02-24T09:08:31.753661Z","iopub.status.idle":"2024-02-24T09:08:31.762644Z","shell.execute_reply.started":"2024-02-24T09:08:31.753628Z","shell.execute_reply":"2024-02-24T09:08:31.761353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import cross_val_score is an alternate to train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# Instantiate best model with best hyperparameters (found with GridSearchCV)\nclf = RandomForestClassifier()\n\n# Cross-validated accuracy score\ncv_acc = cross_val_score(clf,X,y,\n                         cv=5, # 5-fold cross-validation\n                         scoring=\"f1\") # accuracy, precision, recall,f1\ncv_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:16:29.195600Z","iopub.execute_input":"2024-02-24T09:16:29.195986Z","iopub.status.idle":"2024-02-24T09:16:34.758541Z","shell.execute_reply.started":"2024-02-24T09:16:29.195957Z","shell.execute_reply":"2024-02-24T09:16:34.757466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_acc = np.mean(cv_acc)\ncv_acc","metadata":{"execution":{"iopub.status.busy":"2024-02-24T09:47:06.316052Z","iopub.execute_input":"2024-02-24T09:47:06.316489Z","iopub.status.idle":"2024-02-24T09:47:06.323780Z","shell.execute_reply.started":"2024-02-24T09:47:06.316459Z","shell.execute_reply":"2024-02-24T09:47:06.322788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We have Random Forest Classifer Model that we can use, let's try some other models\n\n#Modelling\n\n# Put models in a dictionary\nmodels = {\"SVC\" : SVC(random_state=0, probability=True),\n          \"NaiveBayes\": GaussianNB(), \n          \"XGBoost\" : XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')}\n\n# Create function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    # Random seed for reproducible results\n    np.random.seed(42)\n    # Make a list to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(X_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores\n\nmodel_scores2 = fit_and_score(models=models,\n                             X_train=X_train,\n                             X_test=X_valid,\n                             y_train=y_train,\n                             y_test=y_valid)\nmodel_scores2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T10:35:13.951481Z","iopub.execute_input":"2024-02-24T10:35:13.952530Z","iopub.status.idle":"2024-02-24T10:35:24.556510Z","shell.execute_reply.started":"2024-02-24T10:35:13.952494Z","shell.execute_reply":"2024-02-24T10:35:24.555244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Comparison\nmodel_compare = pd.DataFrame(model_scores2, index=['f1'])\nmodel_compare.T.plot.bar();","metadata":{"execution":{"iopub.status.busy":"2024-02-24T10:35:24.558113Z","iopub.execute_input":"2024-02-24T10:35:24.558470Z","iopub.status.idle":"2024-02-24T10:35:24.869785Z","shell.execute_reply.started":"2024-02-24T10:35:24.558441Z","shell.execute_reply":"2024-02-24T10:35:24.868459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We choose SVC and XGBoost for hyperparameter tuning\n\nSVC_hyp = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n            'kernel': ['linear', 'rbf'],\n            'gamma': ['scale', 'auto']}\n\n# Setup random seed\nnp.random.seed(42)\n\n# Setup random hyperparameter search for SVC\nrs_svg = RandomizedSearchCV(SVC(random_state=0, probability=True),\n                                param_distributions=SVC_hyp,\n                                cv=5,\n                                n_iter=20,\n                                verbose=True)\n\n# Fit random hyperparameter search model\nrs_svg.fit(X_train, y_train)\nsvc_best_params = rs_svg.best_params_\nprint(svc_best_params)\nrs_svg.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T10:35:24.871561Z","iopub.execute_input":"2024-02-24T10:35:24.872111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxgboost_hyp = {'n_estimators': [50, 100, 150, 200],\n        'max_depth': [4, 8, 12],\n        'learning_rate': [0.05, 0.1, 0.15]}\n\n# Setup random seed\nnp.random.seed(42)\n\n# Setup random hyperparameter search for LogisticRegression\nrs_xgb = RandomizedSearchCV(XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss'),\n                                param_distributions=xgboost_hyp,\n                                cv=5,\n                                n_iter=20,\n                                verbose=True)\n\n# Fit random hyperparameter search model\nrs_xgb.fit(X_train, y_train)\nxgb_best_params = rs_xgb.best_params_\nprint(xgb_best_params)\nrs_xgb.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:07:19.734637Z","iopub.execute_input":"2024-02-24T11:07:19.735041Z","iopub.status.idle":"2024-02-24T11:07:56.395604Z","shell.execute_reply.started":"2024-02-24T11:07:19.735014Z","shell.execute_reply":"2024-02-24T11:07:56.394430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating\n\n# Check best hyperparameters\nmodel2 = XGBClassifier(random_state=42, \n                       use_label_encoder=False, \n                       eval_metric='logloss',\n                       n_estimators=100,\n                       max_depth=4,\n                       learning_rate=0.1)\nmodel2.fit(X_train,y_train)\nmodel2.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:26:12.265426Z","iopub.execute_input":"2024-02-24T11:26:12.266084Z","iopub.status.idle":"2024-02-24T11:26:12.419521Z","shell.execute_reply.started":"2024-02-24T11:26:12.266044Z","shell.execute_reply":"2024-02-24T11:26:12.418632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make preidctions on test data\ny_preds2 = model2.predict(X_valid)\n\n#Using ROC Curve and AUC Scores\nfrom sklearn.metrics import RocCurveDisplay \n\nRocCurveDisplay.from_estimator(estimator=model2, X=X_valid, y=y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:26:24.256311Z","iopub.execute_input":"2024-02-24T11:26:24.257211Z","iopub.status.idle":"2024-02-24T11:26:24.607494Z","shell.execute_reply.started":"2024-02-24T11:26:24.257173Z","shell.execute_reply":"2024-02-24T11:26:24.606355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting Confusion matrix\n\nsns.set(font_scale=1.5) # Increase font size\n\ndef plot_conf_mat(y_valid, y_preds):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3, 3))\n    ax = sns.heatmap(confusion_matrix(y_valid, y_preds),\n                     annot=True, # Annotate the boxes\n                      fmt='d',\n                     cbar=False)\n    plt.xlabel(\"true label\")\n    plt.ylabel(\"predicted label\")\n    \nplot_conf_mat(y_valid, y_preds2)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:26:52.842182Z","iopub.execute_input":"2024-02-24T11:26:52.842597Z","iopub.status.idle":"2024-02-24T11:26:52.995876Z","shell.execute_reply.started":"2024-02-24T11:26:52.842566Z","shell.execute_reply":"2024-02-24T11:26:52.993796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_valid, y_preds2))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:27:34.116559Z","iopub.execute_input":"2024-02-24T11:27:34.117001Z","iopub.status.idle":"2024-02-24T11:27:34.135253Z","shell.execute_reply.started":"2024-02-24T11:27:34.116968Z","shell.execute_reply":"2024-02-24T11:27:34.133857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.get_params() #","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:28:05.511522Z","iopub.execute_input":"2024-02-24T11:28:05.512546Z","iopub.status.idle":"2024-02-24T11:28:05.520432Z","shell.execute_reply.started":"2024-02-24T11:28:05.512510Z","shell.execute_reply":"2024-02-24T11:28:05.519492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import cross_val_score is an alternate to train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# Instantiate best model with best hyperparameters\nclf2 = XGBClassifier(random_state=42, \n                       use_label_encoder=False, \n                       eval_metric='logloss',\n                       n_estimators=100,\n                       max_depth=4,\n                       learning_rate=0.1)\n\n# Cross-validated accuracy score\ncv_acc2 = cross_val_score(clf2,X,y,\n                         cv=5, # 5-fold cross-validation\n                         scoring=\"f1\") # accuracy, precision, recall,f1\ncv_acc2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:29:48.746791Z","iopub.execute_input":"2024-02-24T11:29:48.747212Z","iopub.status.idle":"2024-02-24T11:29:49.507680Z","shell.execute_reply.started":"2024-02-24T11:29:48.747180Z","shell.execute_reply":"2024-02-24T11:29:49.506854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(cv_acc2) #XGBoost is a best option then RandomForestClassification","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:30:00.945237Z","iopub.execute_input":"2024-02-24T11:30:00.945645Z","iopub.status.idle":"2024-02-24T11:30:00.953045Z","shell.execute_reply.started":"2024-02-24T11:30:00.945614Z","shell.execute_reply":"2024-02-24T11:30:00.951851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modelling\n# Put models in a dictionary\nmodels = {\"LGBM\" : LGBMClassifier(random_state=0),\n            \"CatBoost\" : CatBoostClassifier(random_state=0, verbose=False),\n            \"GradientBoost\": GradientBoostingClassifier(random_state=0)}\n\n# Create function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    # Random seed for reproducible results\n    np.random.seed(42)\n    # Make a list to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(X_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores\n\nmodel_scores3 = fit_and_score(models=models,\n                             X_train=X_train,\n                             X_test=X_valid,\n                             y_train=y_train,\n                             y_test=y_valid)\nmodel_scores3","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:35:54.870878Z","iopub.execute_input":"2024-02-24T11:35:54.871248Z","iopub.status.idle":"2024-02-24T11:36:00.641484Z","shell.execute_reply.started":"2024-02-24T11:35:54.871221Z","shell.execute_reply":"2024-02-24T11:36:00.640343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Comparison\nmodel_compare = pd.DataFrame(model_scores3, index=['f1'])\nmodel_compare.T.plot.bar();","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:36:03.811203Z","iopub.execute_input":"2024-02-24T11:36:03.811600Z","iopub.status.idle":"2024-02-24T11:36:04.097040Z","shell.execute_reply.started":"2024-02-24T11:36:03.811569Z","shell.execute_reply":"2024-02-24T11:36:04.095927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We choose LGMB and CatBoost for hyperparameter tuning\n\n# Define the hyperparameter grid\nboosted_grid = {\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [4, 8, 12],\n    'learning_rate': [0.05, 0.1, 0.15],\n    'num_leaves': [10, 20, 30, 40], \n}\n\n\n# Setup random hyperparameter search for LightGBM\nrs_lgbm = RandomizedSearchCV(\n    LGBMClassifier(random_state=0, verbose=0),\n    param_distributions=boosted_grid,\n    cv=5,\n    n_iter=20,\n    verbose=0,\n    scoring='accuracy',  # Use an appropriate scoring metric\n    random_state=42,\n    n_jobs=-1  # Use multiple cores for parallel processing\n)\n\n# Fit random hyperparameter search model\nrs_lgbm.fit(X_train, y_train)\nlgbm_best_params = rs_lgbm.best_params_\n\n# Evaluate the model on the validation set\naccuracy = rs_lgbm.score(X_valid, y_valid)\nprint(f\"Best Hyperparameters: {lgbm_best_params}\")\nprint(f\"Validation Accuracy: {accuracy}\")\n\n# Now, you can use the best_params_ to create a final LightGBM model for further evaluation\nfinal_lgbm_model = LGBMClassifier(**lgbm_best_params, random_state=0, verbose=0)\nfinal_lgbm_model.fit(X_train, y_train)\nfinal_accuracy = final_lgbm_model.score(X_valid, y_valid)\nprint(f\"Final Model Validation Accuracy: {final_accuracy}\")\n\n\n# Best Hyperparameters: {'num_leaves': 20, 'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.1}\n# Validation Accuracy: 0.8159861989649224\n# Final Model Validation Accuracy: 0.8159861989649224","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:59:14.464325Z","iopub.execute_input":"2024-02-24T11:59:14.464719Z","iopub.status.idle":"2024-02-24T11:59:14.475683Z","shell.execute_reply.started":"2024-02-24T11:59:14.464688Z","shell.execute_reply":"2024-02-24T11:59:14.474131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make preidctions on test data\ny_preds3 = final_lgbm_model.predict(X_valid)\n\n#Using ROC Curve and AUC Scores\nfrom sklearn.metrics import RocCurveDisplay \n\nRocCurveDisplay.from_estimator(estimator=final_lgbm_model, X=X_valid, y=y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:59:33.285259Z","iopub.execute_input":"2024-02-24T11:59:33.286151Z","iopub.status.idle":"2024-02-24T11:59:33.679236Z","shell.execute_reply.started":"2024-02-24T11:59:33.286102Z","shell.execute_reply":"2024-02-24T11:59:33.677990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting Confusion matrix\n\nsns.set(font_scale=1.5) # Increase font size\n\ndef plot_conf_mat(y_valid, y_preds):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3, 3))\n    ax = sns.heatmap(confusion_matrix(y_valid, y_preds),\n                     annot=True, # Annotate the boxes\n                      fmt='d',\n                     cbar=False)\n    plt.xlabel(\"true label\")\n    plt.ylabel(\"predicted label\")\n    \nplot_conf_mat(y_valid, y_preds3)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:59:38.721677Z","iopub.execute_input":"2024-02-24T11:59:38.722085Z","iopub.status.idle":"2024-02-24T11:59:38.873877Z","shell.execute_reply.started":"2024-02-24T11:59:38.722055Z","shell.execute_reply":"2024-02-24T11:59:38.872821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_valid, y_preds3))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:59:44.054712Z","iopub.execute_input":"2024-02-24T11:59:44.055141Z","iopub.status.idle":"2024-02-24T11:59:44.071972Z","shell.execute_reply.started":"2024-02-24T11:59:44.055109Z","shell.execute_reply":"2024-02-24T11:59:44.070735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_lgbm_model.get_params() #","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import cross_val_score is an alternate to train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# Instantiate best model with best hyperparameters\n#clf3 = LGBMClassifier(*lgbm_best_params, random_state=0, verbose=0)\n\n# Cross-validated accuracy score\ncv_acc3 = cross_val_score(final_lgbm_model,X,y,\n                         cv=5, # 5-fold cross-validation\n                         scoring=\"f1\") # accuracy, precision, recall,f1\ncv_acc3","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:00:53.951412Z","iopub.execute_input":"2024-02-24T12:00:53.951852Z","iopub.status.idle":"2024-02-24T12:00:54.551933Z","shell.execute_reply.started":"2024-02-24T12:00:53.951819Z","shell.execute_reply":"2024-02-24T12:00:54.550913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(cv_acc3)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:30:53.174801Z","iopub.execute_input":"2024-02-24T12:30:53.175244Z","iopub.status.idle":"2024-02-24T12:30:53.187215Z","shell.execute_reply.started":"2024-02-24T12:30:53.175205Z","shell.execute_reply":"2024-02-24T12:30:53.185893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We choose LGMB and CatBoost for hyperparameter tuning\n\n# Define the hyperparameter grid\nboosted_grid = {\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [4, 8, 12],\n    'learning_rate': [0.05, 0.1, 0.15] \n}\n\n\n# Setup random hyperparameter search for LightGBM\nrs_cat = RandomizedSearchCV(\n    CatBoostClassifier(random_state=0, verbose=0),\n    param_distributions=boosted_grid,\n    cv=5,\n    n_iter=20,\n    verbose=0,\n    scoring='accuracy',  # Use an appropriate scoring metric\n    random_state=42,\n    n_jobs=-1  # Use multiple cores for parallel processing\n)\n\n# Fit random hyperparameter search model\nrs_cat.fit(X_train, y_train)\ncat_best_params = rs_cat.best_params_\n# Evaluate the model on the validation set\naccuracy = rs_cat.score(X_valid, y_valid)\nprint(f\"Best Hyperparameters: {cat_best_params}\")\nprint(f\"Validation Accuracy: {accuracy}\")\n\n# Now, you can use the best_params_ to create a final LightGBM model for further evaluation\nfinal_catboost_model = CatBoostClassifier(**cat_best_params, random_state=0, verbose=0)\nfinal_catboost_model.fit(X_train, y_train)\nfinal_accuracy_cat = final_catboost_model.score(X_valid, y_valid)\nprint(f\"Final Model Validation Accuracy: {final_accuracy_cat}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:51:56.970385Z","iopub.execute_input":"2024-02-24T11:51:56.970787Z","iopub.status.idle":"2024-02-24T11:55:55.848325Z","shell.execute_reply.started":"2024-02-24T11:51:56.970735Z","shell.execute_reply":"2024-02-24T11:55:55.847111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make preidctions on test data\ny_preds4 = final_catboost_model.predict(X_valid)\n\n#Using ROC Curve and AUC Scores\nfrom sklearn.metrics import RocCurveDisplay \n\nRocCurveDisplay.from_estimator(estimator=final_catboost_model, X=X_valid, y=y_valid)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:18.110924Z","iopub.execute_input":"2024-02-24T11:58:18.111312Z","iopub.status.idle":"2024-02-24T11:58:18.463789Z","shell.execute_reply.started":"2024-02-24T11:58:18.111284Z","shell.execute_reply":"2024-02-24T11:58:18.462639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting Confusion matrix\n\nsns.set(font_scale=1.5) # Increase font size\n\ndef plot_conf_mat(y_valid, y_preds):\n    \"\"\"\n    Plots a confusion matrix using Seaborn's heatmap().\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3, 3))\n    ax = sns.heatmap(confusion_matrix(y_valid, y_preds),\n                     annot=True, # Annotate the boxes\n                      fmt='d',\n                     cbar=False)\n    plt.xlabel(\"true label\")\n    plt.ylabel(\"predicted label\")\n    \nplot_conf_mat(y_valid, y_preds4)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:25.023328Z","iopub.execute_input":"2024-02-24T11:58:25.024172Z","iopub.status.idle":"2024-02-24T11:58:25.173411Z","shell.execute_reply.started":"2024-02-24T11:58:25.024136Z","shell.execute_reply":"2024-02-24T11:58:25.172335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_valid, y_preds4))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:30.963630Z","iopub.execute_input":"2024-02-24T11:58:30.964063Z","iopub.status.idle":"2024-02-24T11:58:30.980700Z","shell.execute_reply.started":"2024-02-24T11:58:30.964030Z","shell.execute_reply":"2024-02-24T11:58:30.979616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_catboost_model.get_params() #","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:40.548441Z","iopub.execute_input":"2024-02-24T11:58:40.548869Z","iopub.status.idle":"2024-02-24T11:58:40.555780Z","shell.execute_reply.started":"2024-02-24T11:58:40.548837Z","shell.execute_reply":"2024-02-24T11:58:40.554703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import cross_val_score is an alternate to train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# Instantiate best model with best hyperparameters\nclf4 = CatBoostClassifier(**cat_best_params, random_state=0, verbose=0)\n\n# Cross-validated accuracy score\ncv_acc4 = cross_val_score(clf4,X,y,\n                         cv=5, # 5-fold cross-validation\n                         scoring=\"f1\") # accuracy, precision, recall,f1\ncv_acc4","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:45.841280Z","iopub.execute_input":"2024-02-24T11:58:45.841988Z","iopub.status.idle":"2024-02-24T11:58:48.156768Z","shell.execute_reply.started":"2024-02-24T11:58:45.841944Z","shell.execute_reply":"2024-02-24T11:58:48.155570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(cv_acc4)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T11:58:50.918052Z","iopub.execute_input":"2024-02-24T11:58:50.918429Z","iopub.status.idle":"2024-02-24T11:58:50.929362Z","shell.execute_reply.started":"2024-02-24T11:58:50.918401Z","shell.execute_reply":"2024-02-24T11:58:50.928274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We go for Light GBM as our main model, we will add and remove features to increase the accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the hyperparameter grid and improving our model further\nboosted_grid = {\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [3, 5, 7, 10],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0],\n    'reg_alpha': [0, 0.1, 0.5, 1.0],\n    'reg_lambda': [0, 0.1, 0.5, 1.0],\n    'min_child_samples': [5, 10, 20],\n    'num_leaves': [20, 31, 40, 50]\n}\n\n\n# Setup random hyperparameter search for LightGBM\nrs_lgbm = RandomizedSearchCV(\n    LGBMClassifier(random_state=0, verbose=0),\n    param_distributions=boosted_grid,\n    cv=5,\n    n_iter=20,\n    verbose=0,\n    scoring='accuracy',\n    random_state=42,\n    n_jobs=-1  \n)\n\n# Fit random hyperparameter search model\nrs_lgbm.fit(X_train, y_train)\nlgbm_best_params = rs_lgbm.best_params_\n\n# Evaluate the model on the validation set\naccuracy = rs_lgbm.score(X_valid, y_valid)\nprint(f\"Best Hyperparameters: {lgbm_best_params}\")\nprint(f\"Validation Accuracy: {accuracy}\")\n\n# Now, you can use the best_params_ to create a final LightGBM model for further evaluation\nfinal_lgbm_model = LGBMClassifier(**lgbm_best_params, random_state=0, verbose=0)\nfinal_lgbm_model.fit(X_train, y_train)\nfinal_accuracy = final_lgbm_model.score(X_valid, y_valid)\nprint(f\"Final Model Validation Accuracy: {final_accuracy}\")\n\n\n# Best Hyperparameters: {'num_leaves': 20, 'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.1}\n# Validation Accuracy: 0.8159861989649224\n# Final Model Validation Accuracy: 0.8159861989649224","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:18:37.734877Z","iopub.execute_input":"2024-02-24T13:18:37.735775Z","iopub.status.idle":"2024-02-24T13:18:55.790664Z","shell.execute_reply.started":"2024-02-24T13:18:37.735713Z","shell.execute_reply":"2024-02-24T13:18:55.789442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n\n# Number of folds in cross-validation\nFOLDS = 10\n\npreds = np.zeros(len(X_test))\nstart = time.time()\n\n# 10-fold cross-validation\ncv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\nscore = 0\n\nfor fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n    # Get training and validation sets\n    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[val_idx]\n\n    # Train model\n    clf = final_lgbm_model\n    clf.fit(X_train, y_train)\n\n    # Make predictions and measure accuracy\n    preds += clf.predict_proba(X_test)[:, 1]\n    score += clf.score(X_valid, y_valid)\n\n# Average accuracy\nscore = score / FOLDS\n\n# Stop timer\nstop = time.time()\n\n# Print accuracy and time\nprint('Model:', 'LightGBM')\nprint('Average validation accuracy:', np.round(100 * score, 2))\nprint('Training time (mins):', np.round((stop - start) / 60, 2))\nprint('')\n\n# Ensemble predictions\npreds = preds / FOLDS","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:47:48.174788Z","iopub.execute_input":"2024-02-24T12:47:48.175212Z","iopub.status.idle":"2024-02-24T12:47:49.716058Z","shell.execute_reply.started":"2024-02-24T12:47:48.175179Z","shell.execute_reply":"2024-02-24T12:47:49.714934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Proportion (in test set) we get from rounding\nprint(np.round(100*np.round(preds).sum()/len(preds),2))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:47:56.371569Z","iopub.execute_input":"2024-02-24T12:47:56.371984Z","iopub.status.idle":"2024-02-24T12:47:56.379278Z","shell.execute_reply.started":"2024-02-24T12:47:56.371951Z","shell.execute_reply":"2024-02-24T12:47:56.377986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Proportion of predicted positive (transported) classes\ndef preds_prop(preds_arr, thresh):\n    pred_classes=(preds_arr>=thresh).astype(int)\n    return pred_classes.sum()/len(pred_classes)\n\n# Plot proportions across a range of thresholds\ndef plot_preds_prop(preds_arr):\n    # Array of thresholds\n    T_array=np.arange(0,1,0.001)\n    \n    # Calculate proportions\n    prop=np.zeros(len(T_array))\n    for i, T in enumerate(T_array):\n        prop[i]=preds_prop(preds_arr, T)\n        \n    # Plot proportions\n    plt.figure(figsize=(10,4))\n    plt.plot(T_array, prop)\n    target_prop=0.519         # Experiment with this value\n    plt.axhline(y=target_prop, color='r', linestyle='--')\n    plt.text(-0.02,0.45,f'Target proportion: {target_prop}', fontsize=14)\n    plt.title('Predicted target distribution vs threshold')\n    plt.xlabel('Threshold')\n    plt.ylabel('Proportion')\n    \n    # Find optimal threshold (the one that leads to the proportion being closest to target_prop)\n    T_opt=T_array[np.abs(prop-target_prop).argmin()]\n    print('Optimal threshold:', T_opt)\n    return T_opt\n    \nT_opt=plot_preds_prop(preds)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:48:09.487524Z","iopub.execute_input":"2024-02-24T12:48:09.487955Z","iopub.status.idle":"2024-02-24T12:48:09.849180Z","shell.execute_reply.started":"2024-02-24T12:48:09.487920Z","shell.execute_reply":"2024-02-24T12:48:09.848184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classify test set using optimal threshold\npreds_tuned=(preds>=T_opt).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:48:14.739885Z","iopub.execute_input":"2024-02-24T12:48:14.740269Z","iopub.status.idle":"2024-02-24T12:48:14.745720Z","shell.execute_reply.started":"2024-02-24T12:48:14.740240Z","shell.execute_reply":"2024-02-24T12:48:14.744455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample submission (to get right format)\nsub=pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n\n# Add predictions\nsub['Transported']=preds_tuned\n\n# Replace 0 to False and 1 to True\nsub=sub.replace({0:False, 1:True})\n\n# Prediction distribution\nplt.figure(figsize=(6,6))\nsub['Transported'].value_counts().plot.pie(explode=[0.1,0.1], autopct='%1.1f%%', shadow=True, textprops={'fontsize':16}).set_title(\"Prediction distribution\")","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:48:19.104555Z","iopub.execute_input":"2024-02-24T12:48:19.104962Z","iopub.status.idle":"2024-02-24T12:48:19.285545Z","shell.execute_reply.started":"2024-02-24T12:48:19.104930Z","shell.execute_reply":"2024-02-24T12:48:19.284213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Output to csv\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T12:49:22.983616Z","iopub.execute_input":"2024-02-24T12:49:22.984057Z","iopub.status.idle":"2024-02-24T12:49:22.995140Z","shell.execute_reply.started":"2024-02-24T12:49:22.984023Z","shell.execute_reply":"2024-02-24T12:49:22.993958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = pd.read_csv('/kaggle/working/submission.csv')\nfinal","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:25:29.886103Z","iopub.execute_input":"2024-02-24T13:25:29.886515Z","iopub.status.idle":"2024-02-24T13:25:29.908604Z","shell.execute_reply.started":"2024-02-24T13:25:29.886487Z","shell.execute_reply":"2024-02-24T13:25:29.907371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}